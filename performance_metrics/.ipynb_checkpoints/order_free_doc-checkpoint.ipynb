{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59401921",
   "metadata": {},
   "source": [
    "# Order-free matching performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b89e1d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generic imports\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import ast\n",
    "import json\n",
    "\n",
    "\n",
    "# Sklearn imports\n",
    "from sklearn.metrics import f1_score, recall_score\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, auc, roc_curve\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52458f3",
   "metadata": {},
   "source": [
    "## Read order-free candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cb9a9ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "picos = 'I' # ['P', 'I', 'O', 'S']\n",
    "match_level = 'doc' # ['doc', 'sent', 'win_5', 'para']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "52278a2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files:  ['Biomedical_or_Dental_Material.json', '.nfs0000000011200a4200000003', 'Classification.json', 'Intellectual_Product.json', 'Biologically_Active_Substance.json', 'Diagnostic_Procedure.json', 'Gene_or_Genome.json', 'Finding.json', 'Functional_Concept.json', 'Medical_Device.json', 'Organic_Chemical.json', 'Laboratory__Procedure.json', 'Manufactured_Object.json', 'train_ebm_intervention.json', 'Professional_Society.json', 'Pharmacologic_Substance.json', 'Therapeutic_or_Preventive_Procedure.json', 'train_ebm_intervention_syn.json', 'Biomedical_Occupation_or_Discipline.json', 'Health_Care_Activity.json', 'Idea_or_Concept.json', 'Temporal_Concept.json']\n"
     ]
    }
   ],
   "source": [
    "order_free_dir = f'/mnt/nas2/results/Results/systematicReview/order_free_matching/EBM_PICO_training_matches/order_free/{match_level}/{picos}'\n",
    "order_free_files = os.listdir(order_free_dir)\n",
    "print('Files: ', order_free_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2a1012ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "order_free_files.remove('.nfs0000000011200a4200000003')\n",
    "#order_free_files.remove('Finding.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "822093ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file... Biomedical_or_Dental_Material.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▍         | 1/21 [00:00<00:13,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file... Classification.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|▉         | 2/21 [00:00<00:08,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file... Intellectual_Product.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|█▍        | 3/21 [00:08<01:05,  3.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file... Biologically_Active_Substance.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|█▉        | 4/21 [00:11<00:56,  3.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file... Diagnostic_Procedure.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██▍       | 5/21 [00:25<01:56,  7.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file... Gene_or_Genome.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|██▊       | 6/21 [00:26<01:18,  5.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file... Finding.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 7/21 [02:12<08:51, 37.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file... Functional_Concept.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 8/21 [02:12<05:38, 26.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file... Medical_Device.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|████▎     | 9/21 [02:16<03:49, 19.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file... Organic_Chemical.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|████▊     | 10/21 [02:18<02:31, 13.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file... Laboratory__Procedure.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████▏    | 11/21 [02:54<03:24, 20.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file... Manufactured_Object.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|█████▋    | 12/21 [02:54<02:09, 14.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file... train_ebm_intervention.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▏   | 13/21 [03:07<01:51, 13.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file... Professional_Society.json\n",
      "Loading file... Pharmacologic_Substance.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|███████▏  | 15/21 [03:12<00:51,  8.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file... Therapeutic_or_Preventive_Procedure.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|███████▌  | 16/21 [07:52<06:21, 76.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file... train_ebm_intervention_syn.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 81%|████████  | 17/21 [07:55<03:47, 56.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file... Biomedical_Occupation_or_Discipline.json\n",
      "Loading file... Health_Care_Activity.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 20/21 [08:08<00:27, 27.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file... Idea_or_Concept.json\n",
      "Loading file... Temporal_Concept.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [08:09<00:00, 23.31s/it]\n"
     ]
    }
   ],
   "source": [
    "orf_loaded_files = dict()\n",
    "\n",
    "for i in tqdm(order_free_files):\n",
    "    \n",
    "    filpath = f'{order_free_dir}/{i}'\n",
    "    print('Loading file...', i)\n",
    "    with open( filpath, 'r' ) as rf:\n",
    "        orf_i = json.load(rf)\n",
    "        orf_loaded_files[i] = orf_i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3482441f",
   "metadata": {},
   "source": [
    "## difference between intervention and intervention syn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3cf821f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_orf(v, par):\n",
    "    \n",
    "    orfs = dict()\n",
    "    \n",
    "    for k_i, v_i in v.items():\n",
    "        # print( k_i ) # example: name_15_3, name_9_9, name_12_8\n",
    "        \n",
    "        if 'Inters. (full)' in v_i and len(v_i['Inters. (full)']) > 0:\n",
    "            \n",
    "            full_inters = v_i['Inters. (full)']\n",
    "            # full_inters.keys() = PMIDs\n",
    "            # full_inters.values() = offsets, tokens\n",
    "\n",
    "            for pmid, matches in full_inters.items():\n",
    "                if len(matches['char offs.']) > 1:\n",
    "                    if pmid not in orfs:\n",
    "                        orfs[pmid] = [ ]\n",
    "                        orfs[pmid].extend( matches['word offs.'] )\n",
    "                    else:\n",
    "                        orfs[pmid].extend( matches['word offs.'] )\n",
    "\n",
    "\n",
    "        if 'Inters. (partial)' in v_i and len(v_i['Inters. (partial)']) > 0 and (par=='both' or par==True):\n",
    "            \n",
    "            par_inters = v_i['Inters. (partial)']\n",
    "            \n",
    "            for pmid, matches in par_inters.items():\n",
    "                if len(matches['char offs.']) > 1:\n",
    "                    if pmid not in orfs:\n",
    "                        orfs[pmid] = [ ]\n",
    "                        orfs[pmid].extend( matches['word offs.'] )\n",
    "                    else:\n",
    "                        orfs[pmid].extend( matches['word offs.'] )\n",
    "    \n",
    "    return orfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6106b436",
   "metadata": {},
   "outputs": [],
   "source": [
    "orfs_dict = dict()\n",
    "\n",
    "for k,v in orf_loaded_files.items():\n",
    "\n",
    "    orf_fetched = get_orf(v, par = False)\n",
    "    orfs_dict[k] = orf_fetched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "97af4965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Offsets in Biomedical_or_Dental_Material.json:  3258\n",
      "Offsets in Classification.json:  8369\n",
      "Offsets in Intellectual_Product.json:  86335\n",
      "Offsets in Biologically_Active_Substance.json:  15494\n",
      "Offsets in Diagnostic_Procedure.json:  33795\n",
      "Offsets in Gene_or_Genome.json:  7226\n",
      "Offsets in Finding.json:  298450\n",
      "Offsets in Functional_Concept.json:  19792\n",
      "Offsets in Medical_Device.json:  10628\n",
      "Offsets in Organic_Chemical.json:  13818\n",
      "Offsets in Laboratory__Procedure.json:  44098\n",
      "Offsets in Manufactured_Object.json:  7624\n",
      "Offsets in train_ebm_intervention.json:  2835\n",
      "Offsets in Professional_Society.json:  8\n",
      "Offsets in Pharmacologic_Substance.json:  37882\n",
      "Offsets in Therapeutic_or_Preventive_Procedure.json:  145151\n",
      "Offsets in train_ebm_intervention_syn.json:  25540\n",
      "Offsets in Biomedical_Occupation_or_Discipline.json:  4425\n",
      "Offsets in Health_Care_Activity.json:  60790\n",
      "Offsets in Idea_or_Concept.json:  13321\n",
      "Offsets in Temporal_Concept.json:  70258\n"
     ]
    }
   ],
   "source": [
    "order_offset_dict = dict()\n",
    "\n",
    "for k,v in orfs_dict.items():\n",
    "    \n",
    "    total_offsets = []\n",
    "    for k_i, v_i in v.items():\n",
    "        total_offsets.extend( v_i )\n",
    "    \n",
    "    order_offset_dict[k] = len(total_offsets)\n",
    "    \n",
    "    print( f'Offsets in {k}: ', len(total_offsets) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d826b420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort dictionary\n",
    "order_offset_sorteddict = dict(sorted(order_offset_dict.items(), key=lambda x: x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "38fdf3df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Professional_Society.json': 8,\n",
       " 'train_ebm_intervention.json': 2835,\n",
       " 'Biomedical_or_Dental_Material.json': 3258,\n",
       " 'Biomedical_Occupation_or_Discipline.json': 4425,\n",
       " 'Gene_or_Genome.json': 7226,\n",
       " 'Manufactured_Object.json': 7624,\n",
       " 'Classification.json': 8369,\n",
       " 'Medical_Device.json': 10628,\n",
       " 'Idea_or_Concept.json': 13321,\n",
       " 'Organic_Chemical.json': 13818,\n",
       " 'Biologically_Active_Substance.json': 15494,\n",
       " 'Functional_Concept.json': 19792,\n",
       " 'train_ebm_intervention_syn.json': 25540,\n",
       " 'Diagnostic_Procedure.json': 33795,\n",
       " 'Pharmacologic_Substance.json': 37882,\n",
       " 'Laboratory__Procedure.json': 44098,\n",
       " 'Health_Care_Activity.json': 60790,\n",
       " 'Temporal_Concept.json': 70258,\n",
       " 'Intellectual_Product.json': 86335,\n",
       " 'Therapeutic_or_Preventive_Procedure.json': 145151,\n",
       " 'Finding.json': 298450}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order_offset_sorteddict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f3616407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of dictionaries loaded:  21\n"
     ]
    }
   ],
   "source": [
    "print( 'Total number of dictionaries loaded: ', len(order_offset_sorteddict) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b12e929",
   "metadata": {},
   "source": [
    "## Load order-bound matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a3afaa96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def order_free_matches(x, orf_offsets):\n",
    "    \n",
    "    labs_modified = []\n",
    "    \n",
    "    for i, (identifier, offs, labs) in enumerate( zip(x.pmid, x.offsets, x.labels) ):\n",
    "             \n",
    "        lab_val = [v for k, v in ast.literal_eval(labs).items()] \n",
    "        off_val = ast.literal_eval(offs) \n",
    "        \n",
    "        if str(identifier) in orf_offsets: \n",
    "            orf_matches =  orf_offsets[ str(identifier) ]\n",
    "            match_indices = [ off_val.index(m) for m in orf_matches ]\n",
    "            for i, l in enumerate(lab_val):\n",
    "                if i in match_indices:\n",
    "                    lab_val[i] = 1\n",
    "                    \n",
    "        labs_modified.append( lab_val )\n",
    "        \n",
    "        \n",
    "    return labs_modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ed3f5366",
   "metadata": {},
   "outputs": [],
   "source": [
    "ob_int = f'/mnt/nas2/results/Results/systematicReview/order_free_matching/EBM_PICO_training_matches/direct/{picos}/lf_ds_intervention_syn.tsv'\n",
    "ob_int_syn = f'/mnt/nas2/results/Results/systematicReview/order_free_matching/EBM_PICO_training_matches/direct/{picos}/lf_ds_intervetion.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6796b351",
   "metadata": {},
   "outputs": [],
   "source": [
    "ob_int_df = pd.read_csv(ob_int, sep='\\t', header=0)\n",
    "ob_int_syn_df = pd.read_csv(ob_int_syn, sep='\\t', header=0)\n",
    "ob_merged_df = pd.concat([ob_int_df,ob_int_syn_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "02f85f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_gt(l):\n",
    "    \n",
    "    labels = l\n",
    "    \n",
    "    if isinstance(labels, str):\n",
    "        labels = ast.literal_eval(labels)\n",
    "        \n",
    "    # convert non-1 fine labels labels to 1's\n",
    "    labels = ['1' if (n != '1' and n != '0') else str(n) for i, n in enumerate(labels) ]\n",
    "    \n",
    "    return labels\n",
    "\n",
    "ob_int_df['i'] = ob_int_df.i.apply(process_gt)\n",
    "ob_int_syn_df['i'] = ob_int_syn_df.i.apply(process_gt)\n",
    "\n",
    "ob_int_df['i_f'] = ob_int_df.i_f.apply(process_gt)\n",
    "ob_int_syn_df['i_f'] = ob_int_syn_df.i_f.apply(process_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "803aa5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch ground truth from the direct matching\n",
    "\n",
    "coarse_int_gt = dict(zip(ob_int_df['pmid'], ob_int_df['i']))\n",
    "fine_int_gt = dict(zip(ob_int_df['pmid'], ob_int_df['i_f']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e05c1bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess order-bound labels\n",
    "\n",
    "def process_ob_labs(l):\n",
    "    \n",
    "    labels = l\n",
    "    \n",
    "    if isinstance( labels, str ):\n",
    "        labels = ast.literal_eval(labels)\n",
    "\n",
    "    labels = [ v for k, v in labels.items() ]\n",
    "    labels = ['0' if n == -1 else str(n) for i, n in enumerate(labels) ]\n",
    "\n",
    "    return labels\n",
    "\n",
    "ob_int_df['labels'] = ob_int_df.labels.apply(process_ob_labs) # order bound matching labels for int source\n",
    "ob_int_syn_df['labels'] = ob_int_syn_df.labels.apply(process_ob_labs) # order bound matching labels for int_syn source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "326e4286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch order-bound predictions for merged dataframes\n",
    "\n",
    "ob_preds_merged = dict()\n",
    "\n",
    "ob_int_dict = dict(zip(ob_int_df['pmid'], ob_int_df['labels']))\n",
    "ob_int_syn_dict = dict(zip(ob_int_syn_df['pmid'], ob_int_syn_df['labels']))\n",
    "\n",
    "for k,v in ob_int_dict.items():\n",
    "\n",
    "    if k not in ob_preds_merged:\n",
    "        ob_preds_merged[k] = []\n",
    "        ob_preds_merged[k] = v\n",
    "\n",
    "    else:\n",
    "        old_pred = ob_preds_merged[k]\n",
    "        new_pred = v\n",
    "        \n",
    "        # merge old and new predictions\n",
    "        merged_predictions = [ max( o,n ) for o,n in zip( old_pred, new_pred ) ]\n",
    "        assert len( old_pred ) == len( new_pred ) == len( merged_predictions )\n",
    "        ob_preds_merged[k] = merged_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "68ba5b65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4802"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len( list(ob_preds_merged.values()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "39cceae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in ob_int_syn_dict.items():\n",
    "\n",
    "    if k not in ob_preds_merged:\n",
    "        ob_preds_merged[k] = []\n",
    "        ob_preds_merged[k] = v\n",
    "\n",
    "    else:\n",
    "        old_pred = ob_preds_merged[k]\n",
    "        new_pred = v\n",
    "\n",
    "        # merge old and new predictions\n",
    "        #print( 'merging the new predictions...' )\n",
    "        merged_predictions = [ max( o,n ) for o,n in zip( old_pred, new_pred ) ]\n",
    "        assert len( old_pred ) == len( new_pred ) == len( merged_predictions )\n",
    "        ob_preds_merged[k] = merged_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee7b1dd",
   "metadata": {},
   "source": [
    "## merge and calculate evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "61079a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(d):\n",
    "    l = [ v for k,v in d.items() ]\n",
    "    l = [item for sublist in l for item in sublist]\n",
    "    l = list(map(int, l))\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "2c7d9258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ground truth : coarse_int_gt, fine_int_gt\n",
    "# ob/direct matching preds :  ob_preds_merged\n",
    "\n",
    "order_bound_preds = flatten( ob_preds_merged )\n",
    "picos_coarse = flatten( coarse_int_gt )\n",
    "picos_fine = flatten( fine_int_gt )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "2dce611e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_preds_ordered( ob_preds, orf_offsets ):\n",
    "    \n",
    "    merged_predictions = dict()\n",
    "    \n",
    "    for k, v in ob_preds.items(): # ob preds are the old preds\n",
    "        \n",
    "        k = str(k)\n",
    "\n",
    "        if k in orf_offsets:\n",
    "            matching_offsets = orf_offsets[k]\n",
    "            old_preds = list( map( int, v ))\n",
    "            new_preds = list( map( int, v ))\n",
    "                             \n",
    "            # add new offsets to the new_preds\n",
    "            for indice in matching_offsets:\n",
    "                new_preds[indice] = 1\n",
    "\n",
    "            merged_predictions[ k ] = new_preds\n",
    "        else:\n",
    "            merged_predictions[ k ] = list( map( int, v ) )\n",
    "    \n",
    "    return merged_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c89ccfc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_orf_ordered = list(order_offset_sorteddict.keys())\n",
    "all_orf_ordered.insert( 0, 'order bound' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f25d2856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix for coarse-grained ground truth and order bound matches\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9295    0.7394    0.8236   1177209\n",
      "           1     0.1635    0.4761    0.2434    125960\n",
      "\n",
      "    accuracy                         0.7139   1303169\n",
      "   macro avg     0.5465    0.6077    0.5335   1303169\n",
      "weighted avg     0.8555    0.7139    0.7675   1303169\n",
      "\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and order bound matches\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9565    0.7385    0.8335   1212904\n",
      "           1     0.1352    0.5492    0.2169     90265\n",
      "\n",
      "    accuracy                         0.7254   1303169\n",
      "   macro avg     0.5459    0.6438    0.5252   1303169\n",
      "weighted avg     0.8997    0.7254    0.7908   1303169\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and Professional_Society.json matches\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9295    0.7394    0.8236   1177209\n",
      "           1     0.1635    0.4761    0.2434    125960\n",
      "\n",
      "    accuracy                         0.7139   1303169\n",
      "   macro avg     0.5465    0.6077    0.5335   1303169\n",
      "weighted avg     0.8555    0.7139    0.7675   1303169\n",
      "\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and Professional_Society.json matches\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9565    0.7385    0.8335   1212904\n",
      "           1     0.1352    0.5492    0.2169     90265\n",
      "\n",
      "    accuracy                         0.7253   1303169\n",
      "   macro avg     0.5458    0.6438    0.5252   1303169\n",
      "weighted avg     0.8997    0.7253    0.7908   1303169\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and train_ebm_intervention.json matches\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9295    0.7392    0.8235   1177209\n",
      "           1     0.1635    0.4764    0.2434    125960\n",
      "\n",
      "    accuracy                         0.7138   1303169\n",
      "   macro avg     0.5465    0.6078    0.5335   1303169\n",
      "weighted avg     0.8555    0.7138    0.7674   1303169\n",
      "\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and train_ebm_intervention.json matches\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9566    0.7383    0.8334   1212904\n",
      "           1     0.1351    0.5496    0.2169     90265\n",
      "\n",
      "    accuracy                         0.7252   1303169\n",
      "   macro avg     0.5459    0.6439    0.5252   1303169\n",
      "weighted avg     0.8997    0.7252    0.7907   1303169\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and Biomedical_or_Dental_Material.json matches\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9296    0.7390    0.8234   1177209\n",
      "           1     0.1636    0.4771    0.2437    125960\n",
      "\n",
      "    accuracy                         0.7137   1303169\n",
      "   macro avg     0.5466    0.6081    0.5335   1303169\n",
      "weighted avg     0.8556    0.7137    0.7674   1303169\n",
      "\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and Biomedical_or_Dental_Material.json matches\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9566    0.7381    0.8333   1212904\n",
      "           1     0.1353    0.5504    0.2171     90265\n",
      "\n",
      "    accuracy                         0.7251   1303169\n",
      "   macro avg     0.5459    0.6443    0.5252   1303169\n",
      "weighted avg     0.8997    0.7251    0.7906   1303169\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and Biomedical_Occupation_or_Discipline.json matches\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9296    0.7385    0.8231   1177209\n",
      "           1     0.1635    0.4775    0.2436    125960\n",
      "\n",
      "    accuracy                         0.7133   1303169\n",
      "   macro avg     0.5465    0.6080    0.5333   1303169\n",
      "weighted avg     0.8556    0.7133    0.7671   1303169\n",
      "\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and Biomedical_Occupation_or_Discipline.json matches\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9567    0.7376    0.8330   1212904\n",
      "           1     0.1351    0.5509    0.2170     90265\n",
      "\n",
      "    accuracy                         0.7247   1303169\n",
      "   macro avg     0.5459    0.6443    0.5250   1303169\n",
      "weighted avg     0.8997    0.7247    0.7903   1303169\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and Gene_or_Genome.json matches\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9296    0.7378    0.8227   1177209\n",
      "           1     0.1632    0.4781    0.2434    125960\n",
      "\n",
      "    accuracy                         0.7127   1303169\n",
      "   macro avg     0.5464    0.6079    0.5330   1303169\n",
      "weighted avg     0.8556    0.7127    0.7667   1303169\n",
      "\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and Gene_or_Genome.json matches\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9567    0.7369    0.8325   1212904\n",
      "           1     0.1350    0.5516    0.2169     90265\n",
      "\n",
      "    accuracy                         0.7241   1303169\n",
      "   macro avg     0.5458    0.6442    0.5247   1303169\n",
      "weighted avg     0.8998    0.7241    0.7899   1303169\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and Manufactured_Object.json matches\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9297    0.7369    0.8221   1177209\n",
      "           1     0.1630    0.4789    0.2432    125960\n",
      "\n",
      "    accuracy                         0.7119   1303169\n",
      "   macro avg     0.5463    0.6079    0.5327   1303169\n",
      "weighted avg     0.8555    0.7119    0.7662   1303169\n",
      "\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and Manufactured_Object.json matches\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9567    0.7360    0.8320   1212904\n",
      "           1     0.1347    0.5525    0.2167     90265\n",
      "\n",
      "    accuracy                         0.7233   1303169\n",
      "   macro avg     0.5457    0.6442    0.5243   1303169\n",
      "weighted avg     0.8998    0.7233    0.7893   1303169\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and Classification.json matches\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9296    0.7364    0.8218   1177209\n",
      "           1     0.1628    0.4791    0.2430    125960\n",
      "\n",
      "    accuracy                         0.7115   1303169\n",
      "   macro avg     0.5462    0.6077    0.5324   1303169\n",
      "weighted avg     0.8555    0.7115    0.7658   1303169\n",
      "\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and Classification.json matches\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9567    0.7355    0.8316   1212904\n",
      "           1     0.1346    0.5527    0.2164     90265\n",
      "\n",
      "    accuracy                         0.7228   1303169\n",
      "   macro avg     0.5456    0.6441    0.5240   1303169\n",
      "weighted avg     0.8998    0.7228    0.7890   1303169\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and Medical_Device.json matches\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9298    0.7358    0.8215   1177209\n",
      "           1     0.1630    0.4811    0.2435    125960\n",
      "\n",
      "    accuracy                         0.7111   1303169\n",
      "   macro avg     0.5464    0.6084    0.5325   1303169\n",
      "weighted avg     0.8557    0.7111    0.7656   1303169\n",
      "\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and Medical_Device.json matches\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9569    0.7349    0.8313   1212904\n",
      "           1     0.1348    0.5551    0.2169     90265\n",
      "\n",
      "    accuracy                         0.7224   1303169\n",
      "   macro avg     0.5458    0.6450    0.5241   1303169\n",
      "weighted avg     0.8999    0.7224    0.7888   1303169\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and Idea_or_Concept.json matches\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9297    0.7330    0.8197   1177209\n",
      "           1     0.1619    0.4819    0.2423    125960\n",
      "\n",
      "    accuracy                         0.7087   1303169\n",
      "   macro avg     0.5458    0.6074    0.5310   1303169\n",
      "weighted avg     0.8555    0.7087    0.7639   1303169\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and Idea_or_Concept.json matches\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9568    0.7322    0.8296   1212904\n",
      "           1     0.1338    0.5559    0.2157     90265\n",
      "\n",
      "    accuracy                         0.7200   1303169\n",
      "   macro avg     0.5453    0.6440    0.5226   1303169\n",
      "weighted avg     0.8998    0.7200    0.7870   1303169\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and Organic_Chemical.json matches\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9299    0.7323    0.8194   1177209\n",
      "           1     0.1622    0.4841    0.2429    125960\n",
      "\n",
      "    accuracy                         0.7084   1303169\n",
      "   macro avg     0.5460    0.6082    0.5312   1303169\n",
      "weighted avg     0.8557    0.7084    0.7637   1303169\n",
      "\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and Organic_Chemical.json matches\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9570    0.7315    0.8292   1212904\n",
      "           1     0.1341    0.5588    0.2163     90265\n",
      "\n",
      "    accuracy                         0.7196   1303169\n",
      "   macro avg     0.5456    0.6452    0.5228   1303169\n",
      "weighted avg     0.9000    0.7196    0.7868   1303169\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and Biologically_Active_Substance.json matches\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9299    0.7320    0.8191   1177209\n",
      "           1     0.1621    0.4846    0.2429    125960\n",
      "\n",
      "    accuracy                         0.7080   1303169\n",
      "   macro avg     0.5460    0.6083    0.5310   1303169\n",
      "weighted avg     0.8557    0.7080    0.7635   1303169\n",
      "\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and Biologically_Active_Substance.json matches\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9571    0.7311    0.8290   1212904\n",
      "           1     0.1340    0.5592    0.2163     90265\n",
      "\n",
      "    accuracy                         0.7192   1303169\n",
      "   macro avg     0.5456    0.6452    0.5226   1303169\n",
      "weighted avg     0.9001    0.7192    0.7865   1303169\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and Functional_Concept.json matches\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9299    0.7295    0.8176   1177209\n",
      "           1     0.1612    0.4857    0.2420    125960\n",
      "\n",
      "    accuracy                         0.7059   1303169\n",
      "   macro avg     0.5455    0.6076    0.5298   1303169\n",
      "weighted avg     0.8556    0.7059    0.7620   1303169\n",
      "\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and Functional_Concept.json matches\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9570    0.7287    0.8274   1212904\n",
      "           1     0.1332    0.5603    0.2153     90265\n",
      "\n",
      "    accuracy                         0.7171   1303169\n",
      "   macro avg     0.5451    0.6445    0.5214   1303169\n",
      "weighted avg     0.9000    0.7171    0.7850   1303169\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and train_ebm_intervention_syn.json matches\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9299    0.7289    0.8172   1177209\n",
      "           1     0.1612    0.4867    0.2421    125960\n",
      "\n",
      "    accuracy                         0.7055   1303169\n",
      "   macro avg     0.5455    0.6078    0.5297   1303169\n",
      "weighted avg     0.8556    0.7055    0.7617   1303169\n",
      "\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and train_ebm_intervention_syn.json matches\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9571    0.7281    0.8271   1212904\n",
      "           1     0.1332    0.5616    0.2154     90265\n",
      "\n",
      "    accuracy                         0.7166   1303169\n",
      "   macro avg     0.5452    0.6449    0.5212   1303169\n",
      "weighted avg     0.9000    0.7166    0.7847   1303169\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and Diagnostic_Procedure.json matches\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9299    0.7267    0.8159   1177209\n",
      "           1     0.1605    0.4883    0.2416    125960\n",
      "\n",
      "    accuracy                         0.7037   1303169\n",
      "   macro avg     0.5452    0.6075    0.5287   1303169\n",
      "weighted avg     0.8556    0.7037    0.7603   1303169\n",
      "\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and Diagnostic_Procedure.json matches\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9571    0.7260    0.8257   1212904\n",
      "           1     0.1327    0.5632    0.2147     90265\n",
      "\n",
      "    accuracy                         0.7147   1303169\n",
      "   macro avg     0.5449    0.6446    0.5202   1303169\n",
      "weighted avg     0.9000    0.7147    0.7834   1303169\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and Pharmacologic_Substance.json matches\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9301    0.7260    0.8154   1177209\n",
      "           1     0.1606    0.4901    0.2419    125960\n",
      "\n",
      "    accuracy                         0.7032   1303169\n",
      "   macro avg     0.5454    0.6080    0.5287   1303169\n",
      "weighted avg     0.8557    0.7032    0.7600   1303169\n",
      "\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and Pharmacologic_Substance.json matches\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9573    0.7252    0.8252   1212904\n",
      "           1     0.1328    0.5654    0.2151     90265\n",
      "\n",
      "    accuracy                         0.7141   1303169\n",
      "   macro avg     0.5450    0.6453    0.5202   1303169\n",
      "weighted avg     0.9002    0.7141    0.7830   1303169\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and Laboratory__Procedure.json matches\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9300    0.7236    0.8139   1177209\n",
      "           1     0.1597    0.4910    0.2411    125960\n",
      "\n",
      "    accuracy                         0.7011   1303169\n",
      "   macro avg     0.5449    0.6073    0.5275   1303169\n",
      "weighted avg     0.8556    0.7011    0.7586   1303169\n",
      "\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and Laboratory__Procedure.json matches\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9573    0.7229    0.8237   1212904\n",
      "           1     0.1320    0.5662    0.2141     90265\n",
      "\n",
      "    accuracy                         0.7121   1303169\n",
      "   macro avg     0.5446    0.6446    0.5189   1303169\n",
      "weighted avg     0.9001    0.7121    0.7815   1303169\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and Health_Care_Activity.json matches\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9300    0.7207    0.8121   1177209\n",
      "           1     0.1589    0.4930    0.2403    125960\n",
      "\n",
      "    accuracy                         0.6987   1303169\n",
      "   macro avg     0.5444    0.6069    0.5262   1303169\n",
      "weighted avg     0.8555    0.6987    0.7568   1303169\n",
      "\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and Health_Care_Activity.json matches\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9573    0.7200    0.8219   1212904\n",
      "           1     0.1312    0.5683    0.2132     90265\n",
      "\n",
      "    accuracy                         0.7095   1303169\n",
      "   macro avg     0.5443    0.6442    0.5176   1303169\n",
      "weighted avg     0.9001    0.7095    0.7797   1303169\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and Temporal_Concept.json matches\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9298    0.7169    0.8096   1177209\n",
      "           1     0.1573    0.4940    0.2386    125960\n",
      "\n",
      "    accuracy                         0.6953   1303169\n",
      "   macro avg     0.5435    0.6054    0.5241   1303169\n",
      "weighted avg     0.8551    0.6953    0.7544   1303169\n",
      "\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and Temporal_Concept.json matches\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9571    0.7162    0.8194   1212904\n",
      "           1     0.1299    0.5691    0.2115     90265\n",
      "\n",
      "    accuracy                         0.7060   1303169\n",
      "   macro avg     0.5435    0.6427    0.5154   1303169\n",
      "weighted avg     0.8998    0.7060    0.7772   1303169\n",
      "\n",
      "--------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix for coarse-grained ground truth and Intellectual_Product.json matches\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9295    0.7106    0.8054   1177209\n",
      "           1     0.1550    0.4962    0.2362    125960\n",
      "\n",
      "    accuracy                         0.6899   1303169\n",
      "   macro avg     0.5423    0.6034    0.5208   1303169\n",
      "weighted avg     0.8546    0.6899    0.7504   1303169\n",
      "\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and Intellectual_Product.json matches\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9570    0.7101    0.8152   1212904\n",
      "           1     0.1279    0.5712    0.2090     90265\n",
      "\n",
      "    accuracy                         0.7005   1303169\n",
      "   macro avg     0.5424    0.6406    0.5121   1303169\n",
      "weighted avg     0.8996    0.7005    0.7733   1303169\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and Therapeutic_or_Preventive_Procedure.json matches\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9298    0.7063    0.8028   1177209\n",
      "           1     0.1545    0.5015    0.2362    125960\n",
      "\n",
      "    accuracy                         0.6865   1303169\n",
      "   macro avg     0.5421    0.6039    0.5195   1303169\n",
      "weighted avg     0.8548    0.6865    0.7480   1303169\n",
      "\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and Therapeutic_or_Preventive_Procedure.json matches\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9573    0.7058    0.8125   1212904\n",
      "           1     0.1274    0.5772    0.2087     90265\n",
      "\n",
      "    accuracy                         0.6969   1303169\n",
      "   macro avg     0.5424    0.6415    0.5106   1303169\n",
      "weighted avg     0.8998    0.6969    0.7707   1303169\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and Finding.json matches\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9289    0.6901    0.7919   1177209\n",
      "           1     0.1488    0.5063    0.2300    125960\n",
      "\n",
      "    accuracy                         0.6723   1303169\n",
      "   macro avg     0.5388    0.5982    0.5109   1303169\n",
      "weighted avg     0.8535    0.6723    0.7376   1303169\n",
      "\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and Finding.json matches\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9568    0.6899    0.8018   1212904\n",
      "           1     0.1225    0.5816    0.2024     90265\n",
      "\n",
      "    accuracy                         0.6824   1303169\n",
      "   macro avg     0.5397    0.6358    0.5021   1303169\n",
      "weighted avg     0.8990    0.6824    0.7602   1303169\n",
      "\n",
      "--------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "base_preds = dict()\n",
    "base_preds_flattened = []\n",
    "\n",
    "\n",
    "for count, i in enumerate(all_orf_ordered):\n",
    "    \n",
    "    # get offsets and merge with the ob ones\n",
    "    if count == 0:\n",
    "        base_preds = ob_preds_merged\n",
    "        base_preds_flattened =  flatten( ob_preds_merged )\n",
    "    else:\n",
    "        # Add more dicts to orderbound preds and modify base_preds_flattened\n",
    "        updated_of_preds = merge_preds_ordered( base_preds, orfs_dict[i] )\n",
    "        base_preds_flattened =  flatten( updated_of_preds )\n",
    "        base_preds = updated_of_preds\n",
    "    \n",
    "    \n",
    "    # Classification report\n",
    "    cr_order_bound_coarse = classification_report( picos_coarse, base_preds_flattened, digits=4  )\n",
    "    print(f'Confusion matrix for coarse-grained ground truth and {i} matches')\n",
    "    print( cr_order_bound_coarse )\n",
    "\n",
    "    cr_order_bound_fine = classification_report( picos_fine, base_preds_flattened, digits=4  )\n",
    "    print(f'\\n\\nConfusion matrix for fine-grained ground truth and {i} matches')\n",
    "    print( cr_order_bound_fine )\n",
    "    \n",
    "    print( '--------------------------------------------------------------------------' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6e76dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041abb7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
