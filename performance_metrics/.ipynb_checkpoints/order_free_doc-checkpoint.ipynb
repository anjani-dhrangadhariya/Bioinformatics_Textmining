{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59401921",
   "metadata": {},
   "source": [
    "# Order-free matching performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b89e1d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generic imports\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import ast\n",
    "import json\n",
    "\n",
    "\n",
    "# Sklearn imports\n",
    "from sklearn.metrics import f1_score, recall_score\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, auc, roc_curve\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52458f3",
   "metadata": {},
   "source": [
    "## Read order-free candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb9a9ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "picos = 'I' # ['P', 'I', 'O', 'S']\n",
    "match_level = 'doc' # ['doc', 'sent', 'win_5', 'para']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52278a2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files:  ['Biomedical_or_Dental_Material.json', '.nfs0000000011200a4200000003', 'Classification.json', 'Intellectual_Product.json', 'Biologically_Active_Substance.json', 'Diagnostic_Procedure.json', 'Gene_or_Genome.json', 'Finding.json', 'Functional_Concept.json', 'Medical_Device.json', 'Organic_Chemical.json', 'Laboratory__Procedure.json', 'Manufactured_Object.json', 'train_ebm_intervention.json', 'Professional_Society.json', 'Pharmacologic_Substance.json', 'Therapeutic_or_Preventive_Procedure.json', 'train_ebm_intervention_syn.json', 'Biomedical_Occupation_or_Discipline.json', 'Health_Care_Activity.json', 'Idea_or_Concept.json', 'Temporal_Concept.json']\n"
     ]
    }
   ],
   "source": [
    "order_free_dir = f'/mnt/nas2/results/Results/systematicReview/order_free_matching/EBM_PICO_training_matches/order_free/{match_level}/{picos}'\n",
    "order_free_files = os.listdir(order_free_dir)\n",
    "print('Files: ', order_free_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a1012ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "order_free_files.remove('.nfs0000000011200a4200000003')\n",
    "#order_free_files.remove('Finding.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "822093ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file... Biomedical_or_Dental_Material.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▌         | 1/20 [00:00<00:15,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file... Classification.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 2/20 [00:01<00:11,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file... Intellectual_Product.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█▌        | 3/20 [00:15<01:59,  7.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file... Biologically_Active_Substance.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 4/20 [00:20<01:34,  5.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file... Diagnostic_Procedure.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 5/20 [00:44<03:09, 12.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file... Gene_or_Genome.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 6/20 [00:53<02:38, 11.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file... Functional_Concept.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|███▌      | 7/20 [00:54<01:41,  7.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file... Medical_Device.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 8/20 [00:57<01:18,  6.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file... Organic_Chemical.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|████▌     | 9/20 [01:08<01:26,  7.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file... Laboratory__Procedure.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 10/20 [01:35<02:16, 13.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file... Manufactured_Object.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|█████▌    | 11/20 [01:35<01:26,  9.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file... train_ebm_intervention.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 12/20 [02:08<02:13, 16.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file... Professional_Society.json\n",
      "Loading file... Pharmacologic_Substance.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 14/20 [02:13<01:00, 10.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file... Therapeutic_or_Preventive_Procedure.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▌  | 15/20 [06:25<05:51, 70.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file... train_ebm_intervention_syn.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 16/20 [06:27<03:29, 52.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file... Biomedical_Occupation_or_Discipline.json\n",
      "Loading file... Health_Care_Activity.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 18/20 [07:32<01:27, 43.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file... Idea_or_Concept.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|█████████▌| 19/20 [07:33<00:33, 33.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file... Temporal_Concept.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [07:33<00:00, 22.69s/it]\n"
     ]
    }
   ],
   "source": [
    "orf_loaded_files = dict()\n",
    "\n",
    "for i in tqdm(order_free_files):\n",
    "    \n",
    "    filpath = f'{order_free_dir}/{i}'\n",
    "    print('Loading file...', i)\n",
    "    with open( filpath, 'r' ) as rf:\n",
    "        orf_i = json.load(rf)\n",
    "        orf_loaded_files[i] = orf_i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3482441f",
   "metadata": {},
   "source": [
    "## difference between intervention and intervention syn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3cf821f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_orf(v, par):\n",
    "    \n",
    "    orfs = dict()\n",
    "    \n",
    "    for k_i, v_i in v.items():\n",
    "        # print( k_i ) # example: name_15_3, name_9_9, name_12_8\n",
    "        \n",
    "        if 'Inters. (full)' in v_i and len(v_i['Inters. (full)']) > 0:\n",
    "            \n",
    "            full_inters = v_i['Inters. (full)']\n",
    "            # full_inters.keys() = PMIDs\n",
    "            # full_inters.values() = offsets, tokens\n",
    "\n",
    "            for pmid, matches in full_inters.items():\n",
    "                if len(matches['char offs.']) > 1:\n",
    "                    if pmid not in orfs:\n",
    "                        orfs[pmid] = [ ]\n",
    "                        orfs[pmid].extend( matches['word offs.'] )\n",
    "                    else:\n",
    "                        orfs[pmid].extend( matches['word offs.'] )\n",
    "\n",
    "\n",
    "        if 'Inters. (partial)' in v_i and len(v_i['Inters. (partial)']) > 0 and (par=='both' or par==True):\n",
    "            \n",
    "            par_inters = v_i['Inters. (partial)']\n",
    "            \n",
    "            for pmid, matches in par_inters.items():\n",
    "                if len(matches['char offs.']) > 1:\n",
    "                    if pmid not in orfs:\n",
    "                        orfs[pmid] = [ ]\n",
    "                        orfs[pmid].extend( matches['word offs.'] )\n",
    "                    else:\n",
    "                        orfs[pmid].extend( matches['word offs.'] )\n",
    "    \n",
    "    return orfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6106b436",
   "metadata": {},
   "outputs": [],
   "source": [
    "orfs_dict = dict()\n",
    "\n",
    "for k,v in orf_loaded_files.items():\n",
    "\n",
    "    orf_fetched = get_orf(v, par = False)\n",
    "    orfs_dict[k] = orf_fetched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b8b17bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Offsets in Biomedical_or_Dental_Material.json:  295455\n",
      "Offsets in Classification.json:  237458\n",
      "Offsets in Intellectual_Product.json:  6967145\n",
      "Offsets in Biologically_Active_Substance.json:  1940567\n",
      "Offsets in Diagnostic_Procedure.json:  10156752\n",
      "Offsets in Gene_or_Genome.json:  858045\n",
      "Offsets in Functional_Concept.json:  472272\n",
      "Offsets in Medical_Device.json:  2808545\n",
      "Offsets in Organic_Chemical.json:  1344269\n",
      "Offsets in Laboratory__Procedure.json:  9981454\n",
      "Offsets in Manufactured_Object.json:  411079\n",
      "Offsets in train_ebm_intervention.json:  28661\n",
      "Offsets in Professional_Society.json:  1166\n",
      "Offsets in Pharmacologic_Substance.json:  3721091\n",
      "Offsets in Therapeutic_or_Preventive_Procedure.json:  85654585\n",
      "Offsets in train_ebm_intervention_syn.json:  107195\n",
      "Offsets in Biomedical_Occupation_or_Discipline.json:  39542\n",
      "Offsets in Health_Care_Activity.json:  14589232\n",
      "Offsets in Idea_or_Concept.json:  178093\n",
      "Offsets in Temporal_Concept.json:  689148\n"
     ]
    }
   ],
   "source": [
    "order_offset_dict = dict()\n",
    "\n",
    "for k,v in orfs_dict.items():\n",
    "    \n",
    "    total_offsets = []\n",
    "    for k_i, v_i in v.items():\n",
    "        total_offsets.extend( v_i )\n",
    "    \n",
    "    order_offset_dict[k] = len(total_offsets)\n",
    "    \n",
    "    print( f'Offsets in {k}: ', len(total_offsets) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6e1ea1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort dictionary\n",
    "order_offset_sorteddict = dict(sorted(order_offset_dict.items(), key=lambda x: x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "871b2674",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Professional_Society.json': 1166,\n",
       " 'train_ebm_intervention.json': 28661,\n",
       " 'Biomedical_Occupation_or_Discipline.json': 39542,\n",
       " 'train_ebm_intervention_syn.json': 107195,\n",
       " 'Idea_or_Concept.json': 178093,\n",
       " 'Classification.json': 237458,\n",
       " 'Biomedical_or_Dental_Material.json': 295455,\n",
       " 'Manufactured_Object.json': 411079,\n",
       " 'Functional_Concept.json': 472272,\n",
       " 'Temporal_Concept.json': 689148,\n",
       " 'Gene_or_Genome.json': 858045,\n",
       " 'Organic_Chemical.json': 1344269,\n",
       " 'Biologically_Active_Substance.json': 1940567,\n",
       " 'Medical_Device.json': 2808545,\n",
       " 'Pharmacologic_Substance.json': 3721091,\n",
       " 'Intellectual_Product.json': 6967145,\n",
       " 'Laboratory__Procedure.json': 9981454,\n",
       " 'Diagnostic_Procedure.json': 10156752,\n",
       " 'Health_Care_Activity.json': 14589232,\n",
       " 'Therapeutic_or_Preventive_Procedure.json': 85654585}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order_offset_sorteddict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72beb496",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a419cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FullMergeDict(D1, D2):\n",
    "    \n",
    "    D_merged = dict()\n",
    "    \n",
    "    for k,v in D1.items():\n",
    "        \n",
    "        if k not in D_merged:\n",
    "            D_merged[k] = []\n",
    "            D_merged[k].extend( v )\n",
    "        else:\n",
    "            D_merged[k].extend( v )\n",
    "\n",
    "    for k,v in D2.items():\n",
    "\n",
    "        if k not in D_merged:\n",
    "            D_merged[k] = []\n",
    "            D_merged[k].extend( v )\n",
    "        else:\n",
    "            D_merged[k].extend( v )\n",
    "            \n",
    "    return D_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce0cd0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "orfs_merged = FullMergeDict( orf_int, orf_int_syn )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6c8cd047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total offsets after the int. and int. syn offsets were merged:  135856\n"
     ]
    }
   ],
   "source": [
    "total_offsets_merged = []\n",
    "for k,v in orfs_merged.items():\n",
    "    total_offsets_merged.extend( v )\n",
    "    \n",
    "print('Total offsets after the int. and int. syn offsets were merged: ', len(total_offsets_merged) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b12e929",
   "metadata": {},
   "source": [
    "## Load order-bound matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a3afaa96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def order_free_matches(x, orf_offsets):\n",
    "    \n",
    "    labs_modified = []\n",
    "    \n",
    "    for i, (identifier, offs, labs) in enumerate( zip(x.pmid, x.offsets, x.labels) ):\n",
    "             \n",
    "        lab_val = [v for k, v in ast.literal_eval(labs).items()] \n",
    "        off_val = ast.literal_eval(offs) \n",
    "        \n",
    "        if str(identifier) in orf_offsets: \n",
    "            orf_matches =  orf_offsets[ str(identifier) ]\n",
    "            match_indices = [ off_val.index(m) for m in orf_matches ]\n",
    "            for i, l in enumerate(lab_val):\n",
    "                if i in match_indices:\n",
    "                    lab_val[i] = 1\n",
    "                    \n",
    "        labs_modified.append( lab_val )\n",
    "        \n",
    "        \n",
    "    return labs_modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ed3f5366",
   "metadata": {},
   "outputs": [],
   "source": [
    "ob_int = f'/mnt/nas2/results/Results/systematicReview/order_free_matching/EBM_PICO_training_matches/direct/{picos}/lf_ds_intervention_syn.tsv'\n",
    "ob_int_syn = f'/mnt/nas2/results/Results/systematicReview/order_free_matching/EBM_PICO_training_matches/direct/{picos}/lf_ds_intervetion.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6796b351",
   "metadata": {},
   "outputs": [],
   "source": [
    "ob_int_df = pd.read_csv(ob_int, sep='\\t', header=0)\n",
    "ob_int_syn_df = pd.read_csv(ob_int_syn, sep='\\t', header=0)\n",
    "ob_merged_df = pd.concat([ob_int_df,ob_int_syn_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "02f85f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_gt(l):\n",
    "    \n",
    "    labels = l\n",
    "    \n",
    "    if isinstance(labels, str):\n",
    "        labels = ast.literal_eval(labels)\n",
    "        \n",
    "    # convert non-1 fine labels labels to 1's\n",
    "    labels = ['1' if (n != '1' and n != '0') else str(n) for i, n in enumerate(labels) ]\n",
    "    \n",
    "    return labels\n",
    "\n",
    "ob_int_df['i'] = ob_int_df.i.apply(process_gt)\n",
    "ob_int_syn_df['i'] = ob_int_syn_df.i.apply(process_gt)\n",
    "\n",
    "ob_int_df['i_f'] = ob_int_df.i_f.apply(process_gt)\n",
    "ob_int_syn_df['i_f'] = ob_int_syn_df.i_f.apply(process_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "803aa5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch ground truth from the direct matching\n",
    "\n",
    "coarse_int_gt = dict(zip(ob_int_df['pmid'], ob_int_df['i']))\n",
    "fine_int_gt = dict(zip(ob_int_df['pmid'], ob_int_df['i_f']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e05c1bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess order-bound labels\n",
    "\n",
    "def process_ob_labs(l):\n",
    "    \n",
    "    labels = l\n",
    "    \n",
    "    if isinstance( labels, str ):\n",
    "        labels = ast.literal_eval(labels)\n",
    "\n",
    "    labels = [ v for k, v in labels.items() ]\n",
    "    labels = ['0' if n == -1 else str(n) for i, n in enumerate(labels) ]\n",
    "\n",
    "    return labels\n",
    "\n",
    "ob_int_df['labels'] = ob_int_df.labels.apply(process_ob_labs) # order bound matching labels for int source\n",
    "ob_int_syn_df['labels'] = ob_int_syn_df.labels.apply(process_ob_labs) # order bound matching labels for int_syn source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "326e4286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch order-bound predictions for merged dataframes\n",
    "\n",
    "ob_preds_merged = dict()\n",
    "\n",
    "ob_int_dict = dict(zip(ob_int_df['pmid'], ob_int_df['labels']))\n",
    "ob_int_syn_dict = dict(zip(ob_int_syn_df['pmid'], ob_int_syn_df['labels']))\n",
    "\n",
    "for k,v in ob_int_dict.items():\n",
    "\n",
    "    if k not in ob_preds_merged:\n",
    "        ob_preds_merged[k] = []\n",
    "        ob_preds_merged[k] = v\n",
    "\n",
    "    else:\n",
    "        old_pred = ob_preds_merged[k]\n",
    "        new_pred = v\n",
    "        \n",
    "        # merge old and new predictions\n",
    "        merged_predictions = [ max( o,n ) for o,n in zip( old_pred, new_pred ) ]\n",
    "        assert len( old_pred ) == len( new_pred ) == len( merged_predictions )\n",
    "        ob_preds_merged[k] = merged_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "68ba5b65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4802"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len( list(ob_preds_merged.values()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "39cceae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in ob_int_syn_dict.items():\n",
    "\n",
    "    if k not in ob_preds_merged:\n",
    "        ob_preds_merged[k] = []\n",
    "        ob_preds_merged[k] = v\n",
    "\n",
    "    else:\n",
    "        old_pred = ob_preds_merged[k]\n",
    "        new_pred = v\n",
    "\n",
    "        # merge old and new predictions\n",
    "        #print( 'merging the new predictions...' )\n",
    "        merged_predictions = [ max( o,n ) for o,n in zip( old_pred, new_pred ) ]\n",
    "        assert len( old_pred ) == len( new_pred ) == len( merged_predictions )\n",
    "        ob_preds_merged[k] = merged_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee7b1dd",
   "metadata": {},
   "source": [
    "## merge and calculate evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "61079a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(d):\n",
    "    l = [ v for k,v in d.items() ]\n",
    "    l = [item for sublist in l for item in sublist]\n",
    "    l = list(map(int, l))\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2c7d9258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ground truth : coarse_int_gt, fine_int_gt\n",
    "# ob/direct matching preds :  ob_preds_merged\n",
    "\n",
    "order_bound_preds = flatten( ob_preds_merged )\n",
    "picos_coarse = flatten( coarse_int_gt )\n",
    "picos_fine = flatten( fine_int_gt )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e935ce00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_preds_ordered( ob_preds, orf_offsets ):\n",
    "    \n",
    "    merged_predictions = dict()\n",
    "    \n",
    "    for k, v in ob_preds.items(): # ob preds are the old preds\n",
    "        \n",
    "        k = str(k)\n",
    "\n",
    "        if k in orf_offsets:\n",
    "            matching_offsets = orf_offsets[k]\n",
    "            old_preds = list( map( int, v ))\n",
    "            new_preds = list( map( int, v ))\n",
    "                             \n",
    "            # add new offsets to the new_preds\n",
    "            for indice in matching_offsets:\n",
    "                new_preds[indice] = 1\n",
    "\n",
    "            merged_predictions[ k ] = new_preds\n",
    "        else:\n",
    "            merged_predictions[ k ] = list( map( int, v ) )\n",
    "    \n",
    "    return merged_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a34da06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_orf_ordered = list(order_offset_sorteddict.keys())\n",
    "all_orf_ordered.insert( 0, 'order bound' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f25d2856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix for coarse-grained ground truth and order bound matches\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9295    0.7394    0.8236   1177209\n",
      "           1     0.1635    0.4761    0.2434    125960\n",
      "\n",
      "    accuracy                         0.7139   1303169\n",
      "   macro avg     0.5465    0.6077    0.5335   1303169\n",
      "weighted avg     0.8555    0.7139    0.7675   1303169\n",
      "\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and order bound matches\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9565    0.7385    0.8335   1212904\n",
      "           1     0.1352    0.5492    0.2169     90265\n",
      "\n",
      "    accuracy                         0.7254   1303169\n",
      "   macro avg     0.5459    0.6438    0.5252   1303169\n",
      "weighted avg     0.8997    0.7254    0.7908   1303169\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and Professional_Society.json matches\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9295    0.7391    0.8234   1177209\n",
      "           1     0.1634    0.4762    0.2433    125960\n",
      "\n",
      "    accuracy                         0.7137   1303169\n",
      "   macro avg     0.5465    0.6077    0.5334   1303169\n",
      "weighted avg     0.8555    0.7137    0.7674   1303169\n",
      "\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and Professional_Society.json matches\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9565    0.7382    0.8333   1212904\n",
      "           1     0.1351    0.5494    0.2168     90265\n",
      "\n",
      "    accuracy                         0.7251   1303169\n",
      "   macro avg     0.5458    0.6438    0.5251   1303169\n",
      "weighted avg     0.8996    0.7251    0.7906   1303169\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and train_ebm_intervention.json matches\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9295    0.7366    0.8219   1177209\n",
      "           1     0.1627    0.4781    0.2427    125960\n",
      "\n",
      "    accuracy                         0.7116   1303169\n",
      "   macro avg     0.5461    0.6074    0.5323   1303169\n",
      "weighted avg     0.8554    0.7116    0.7659   1303169\n",
      "\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and train_ebm_intervention.json matches\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9566    0.7358    0.8318   1212904\n",
      "           1     0.1344    0.5513    0.2161     90265\n",
      "\n",
      "    accuracy                         0.7230   1303169\n",
      "   macro avg     0.5455    0.6435    0.5239   1303169\n",
      "weighted avg     0.8996    0.7230    0.7891   1303169\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and Biomedical_Occupation_or_Discipline.json matches\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9295    0.7351    0.8209   1177209\n",
      "           1     0.1622    0.4792    0.2423    125960\n",
      "\n",
      "    accuracy                         0.7103   1303169\n",
      "   macro avg     0.5458    0.6071    0.5316   1303169\n",
      "weighted avg     0.8554    0.7103    0.7650   1303169\n",
      "\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and Biomedical_Occupation_or_Discipline.json matches\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9566    0.7342    0.8308   1212904\n",
      "           1     0.1340    0.5526    0.2157     90265\n",
      "\n",
      "    accuracy                         0.7217   1303169\n",
      "   macro avg     0.5453    0.6434    0.5233   1303169\n",
      "weighted avg     0.8996    0.7217    0.7882   1303169\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and train_ebm_intervention_syn.json matches\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9296    0.7298    0.8177   1177209\n",
      "           1     0.1606    0.4832    0.2411    125960\n",
      "\n",
      "    accuracy                         0.7060   1303169\n",
      "   macro avg     0.5451    0.6065    0.5294   1303169\n",
      "weighted avg     0.8552    0.7060    0.7619   1303169\n",
      "\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and train_ebm_intervention_syn.json matches\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9567    0.7290    0.8275   1212904\n",
      "           1     0.1326    0.5566    0.2141     90265\n",
      "\n",
      "    accuracy                         0.7170   1303169\n",
      "   macro avg     0.5446    0.6428    0.5208   1303169\n",
      "weighted avg     0.8996    0.7170    0.7850   1303169\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and Idea_or_Concept.json matches\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9290    0.7161    0.8088   1177209\n",
      "           1     0.1555    0.4884    0.2358    125960\n",
      "\n",
      "    accuracy                         0.6941   1303169\n",
      "   macro avg     0.5422    0.6023    0.5223   1303169\n",
      "weighted avg     0.8542    0.6941    0.7534   1303169\n",
      "\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and Idea_or_Concept.json matches\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9564    0.7155    0.8186   1212904\n",
      "           1     0.1280    0.5613    0.2085     90265\n",
      "\n",
      "    accuracy                         0.7049   1303169\n",
      "   macro avg     0.5422    0.6384    0.5136   1303169\n",
      "weighted avg     0.8990    0.7049    0.7763   1303169\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and Classification.json matches\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9288    0.7097    0.8046   1177209\n",
      "           1     0.1533    0.4912    0.2337    125960\n",
      "\n",
      "    accuracy                         0.6886   1303169\n",
      "   macro avg     0.5410    0.6004    0.5191   1303169\n",
      "weighted avg     0.8538    0.6886    0.7494   1303169\n",
      "\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and Classification.json matches\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9563    0.7092    0.8144   1212904\n",
      "           1     0.1262    0.5641    0.2062     90265\n",
      "\n",
      "    accuracy                         0.6992   1303169\n",
      "   macro avg     0.5412    0.6367    0.5103   1303169\n",
      "weighted avg     0.8988    0.6992    0.7723   1303169\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and Biomedical_or_Dental_Material.json matches\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9290    0.7079    0.8035   1177209\n",
      "           1     0.1533    0.4943    0.2340    125960\n",
      "\n",
      "    accuracy                         0.6872   1303169\n",
      "   macro avg     0.5411    0.6011    0.5187   1303169\n",
      "weighted avg     0.8540    0.6872    0.7484   1303169\n",
      "\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and Biomedical_or_Dental_Material.json matches\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9565    0.7074    0.8133   1212904\n",
      "           1     0.1262    0.5678    0.2065     90265\n",
      "\n",
      "    accuracy                         0.6977   1303169\n",
      "   macro avg     0.5413    0.6376    0.5099   1303169\n",
      "weighted avg     0.8990    0.6977    0.7713   1303169\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and Manufactured_Object.json matches\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9290    0.7037    0.8008   1177209\n",
      "           1     0.1523    0.4977    0.2333    125960\n",
      "\n",
      "    accuracy                         0.6838   1303169\n",
      "   macro avg     0.5407    0.6007    0.5171   1303169\n",
      "weighted avg     0.8540    0.6838    0.7460   1303169\n",
      "\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and Manufactured_Object.json matches\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9566    0.7033    0.8106   1212904\n",
      "           1     0.1254    0.5714    0.2056     90265\n",
      "\n",
      "    accuracy                         0.6942   1303169\n",
      "   macro avg     0.5410    0.6374    0.5081   1303169\n",
      "weighted avg     0.8990    0.6942    0.7687   1303169\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and Functional_Concept.json matches\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9288    0.6966    0.7961   1177209\n",
      "           1     0.1501    0.5009    0.2310    125960\n",
      "\n",
      "    accuracy                         0.6777   1303169\n",
      "   macro avg     0.5395    0.5988    0.5136   1303169\n",
      "weighted avg     0.8535    0.6777    0.7415   1303169\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and Functional_Concept.json matches\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9565    0.6962    0.8059   1212904\n",
      "           1     0.1234    0.5744    0.2031     90265\n",
      "\n",
      "    accuracy                         0.6878   1303169\n",
      "   macro avg     0.5399    0.6353    0.5045   1303169\n",
      "weighted avg     0.8988    0.6878    0.7641   1303169\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and Temporal_Concept.json matches\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9284    0.6891    0.7911   1177209\n",
      "           1     0.1476    0.5033    0.2283    125960\n",
      "\n",
      "    accuracy                         0.6711   1303169\n",
      "   macro avg     0.5380    0.5962    0.5097   1303169\n",
      "weighted avg     0.8529    0.6711    0.7367   1303169\n",
      "\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and Temporal_Concept.json matches\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9562    0.6889    0.8008   1212904\n",
      "           1     0.1212    0.5764    0.2003     90265\n",
      "\n",
      "    accuracy                         0.6811   1303169\n",
      "   macro avg     0.5387    0.6327    0.5006   1303169\n",
      "weighted avg     0.8984    0.6811    0.7592   1303169\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and Gene_or_Genome.json matches\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9284    0.6852    0.7884   1177209\n",
      "           1     0.1467    0.5060    0.2275    125960\n",
      "\n",
      "    accuracy                         0.6678   1303169\n",
      "   macro avg     0.5376    0.5956    0.5080   1303169\n",
      "weighted avg     0.8528    0.6678    0.7342   1303169\n",
      "\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and Gene_or_Genome.json matches\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9563    0.6850    0.7982   1212904\n",
      "           1     0.1204    0.5794    0.1994     90265\n",
      "\n",
      "    accuracy                         0.6777   1303169\n",
      "   macro avg     0.5383    0.6322    0.4988   1303169\n",
      "weighted avg     0.8984    0.6777    0.7567   1303169\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and Organic_Chemical.json matches\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9288    0.6831    0.7872   1177209\n",
      "           1     0.1470    0.5107    0.2283    125960\n",
      "\n",
      "    accuracy                         0.6664   1303169\n",
      "   macro avg     0.5379    0.5969    0.5078   1303169\n",
      "weighted avg     0.8532    0.6664    0.7332   1303169\n",
      "\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and Organic_Chemical.json matches\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9567    0.6829    0.7970   1212904\n",
      "           1     0.1207    0.5851    0.2002     90265\n",
      "\n",
      "    accuracy                         0.6761   1303169\n",
      "   macro avg     0.5387    0.6340    0.4986   1303169\n",
      "weighted avg     0.8988    0.6761    0.7556   1303169\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and Biologically_Active_Substance.json matches\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9288    0.6811    0.7859   1177209\n",
      "           1     0.1465    0.5117    0.2278    125960\n",
      "\n",
      "    accuracy                         0.6647   1303169\n",
      "   macro avg     0.5376    0.5964    0.5068   1303169\n",
      "weighted avg     0.8531    0.6647    0.7319   1303169\n",
      "\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and Biologically_Active_Substance.json matches\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9567    0.6810    0.7956   1212904\n",
      "           1     0.1203    0.5862    0.1996     90265\n",
      "\n",
      "    accuracy                         0.6744   1303169\n",
      "   macro avg     0.5385    0.6336    0.4976   1303169\n",
      "weighted avg     0.8988    0.6744    0.7544   1303169\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and Medical_Device.json matches\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9290    0.6734    0.7808   1177209\n",
      "           1     0.1453    0.5191    0.2271    125960\n",
      "\n",
      "    accuracy                         0.6585   1303169\n",
      "   macro avg     0.5372    0.5962    0.5040   1303169\n",
      "weighted avg     0.8533    0.6585    0.7273   1303169\n",
      "\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and Medical_Device.json matches\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9571    0.6733    0.7905   1212904\n",
      "           1     0.1192    0.5943    0.1986     90265\n",
      "\n",
      "    accuracy                         0.6679   1303169\n",
      "   macro avg     0.5382    0.6338    0.4946   1303169\n",
      "weighted avg     0.8990    0.6679    0.7495   1303169\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and Pharmacologic_Substance.json matches\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9291    0.6714    0.7795   1177209\n",
      "           1     0.1451    0.5213    0.2270    125960\n",
      "\n",
      "    accuracy                         0.6569   1303169\n",
      "   macro avg     0.5371    0.5964    0.5033   1303169\n",
      "weighted avg     0.8533    0.6569    0.7261   1303169\n",
      "\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and Pharmacologic_Substance.json matches\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9572    0.6714    0.7892   1212904\n",
      "           1     0.1190    0.5967    0.1985     90265\n",
      "\n",
      "    accuracy                         0.6662   1303169\n",
      "   macro avg     0.5381    0.6341    0.4939   1303169\n",
      "weighted avg     0.8992    0.6662    0.7483   1303169\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and Intellectual_Product.json matches\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9279    0.6470    0.7624   1177209\n",
      "           1     0.1384    0.5300    0.2195    125960\n",
      "\n",
      "    accuracy                         0.6357   1303169\n",
      "   macro avg     0.5332    0.5885    0.4910   1303169\n",
      "weighted avg     0.8516    0.6357    0.7099   1303169\n",
      "\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and Intellectual_Product.json matches\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9566    0.6474    0.7722   1212904\n",
      "           1     0.1133    0.6055    0.1909     90265\n",
      "\n",
      "    accuracy                         0.6445   1303169\n",
      "   macro avg     0.5350    0.6265    0.4816   1303169\n",
      "weighted avg     0.8982    0.6445    0.7320   1303169\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and Laboratory__Procedure.json matches\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9277    0.6410    0.7581   1177209\n",
      "           1     0.1370    0.5328    0.2180    125960\n",
      "\n",
      "    accuracy                         0.6305   1303169\n",
      "   macro avg     0.5323    0.5869    0.4881   1303169\n",
      "weighted avg     0.8512    0.6305    0.7059   1303169\n",
      "\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and Laboratory__Procedure.json matches\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9565    0.6415    0.7679   1212904\n",
      "           1     0.1121    0.6081    0.1893     90265\n",
      "\n",
      "    accuracy                         0.6391   1303169\n",
      "   macro avg     0.5343    0.6248    0.4786   1303169\n",
      "weighted avg     0.8980    0.6391    0.7278   1303169\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and Diagnostic_Procedure.json matches\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9276    0.6359    0.7545   1177209\n",
      "           1     0.1361    0.5361    0.2171    125960\n",
      "\n",
      "    accuracy                         0.6262   1303169\n",
      "   macro avg     0.5318    0.5860    0.4858   1303169\n",
      "weighted avg     0.8511    0.6262    0.7026   1303169\n",
      "\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and Diagnostic_Procedure.json matches\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9566    0.6364    0.7643   1212904\n",
      "           1     0.1113    0.6117    0.1883     90265\n",
      "\n",
      "    accuracy                         0.6347   1303169\n",
      "   macro avg     0.5339    0.6241    0.4763   1303169\n",
      "weighted avg     0.8980    0.6347    0.7244   1303169\n",
      "\n",
      "--------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix for coarse-grained ground truth and Health_Care_Activity.json matches\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9267    0.6176    0.7412   1177209\n",
      "           1     0.1321    0.5437    0.2125    125960\n",
      "\n",
      "    accuracy                         0.6105   1303169\n",
      "   macro avg     0.5294    0.5807    0.4769   1303169\n",
      "weighted avg     0.8499    0.6105    0.6901   1303169\n",
      "\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and Health_Care_Activity.json matches\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9562    0.6185    0.7511   1212904\n",
      "           1     0.1077    0.6191    0.1835     90265\n",
      "\n",
      "    accuracy                         0.6185   1303169\n",
      "   macro avg     0.5320    0.6188    0.4673   1303169\n",
      "weighted avg     0.8974    0.6185    0.7118   1303169\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and Therapeutic_or_Preventive_Procedure.json matches\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9268    0.6132    0.7381   1177209\n",
      "           1     0.1316    0.5476    0.2121    125960\n",
      "\n",
      "    accuracy                         0.6069   1303169\n",
      "   macro avg     0.5292    0.5804    0.4751   1303169\n",
      "weighted avg     0.8500    0.6069    0.6873   1303169\n",
      "\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and Therapeutic_or_Preventive_Procedure.json matches\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9564    0.6141    0.7480   1212904\n",
      "           1     0.1073    0.6235    0.1832     90265\n",
      "\n",
      "    accuracy                         0.6148   1303169\n",
      "   macro avg     0.5319    0.6188    0.4656   1303169\n",
      "weighted avg     0.8976    0.6148    0.7088   1303169\n",
      "\n",
      "--------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "base_preds = dict()\n",
    "base_preds_flattened = []\n",
    "\n",
    "\n",
    "for count, i in enumerate(all_orf_ordered):\n",
    "    \n",
    "    # get offsets and merge with the ob ones\n",
    "    if count == 0:\n",
    "        base_preds = ob_preds_merged\n",
    "        base_preds_flattened =  flatten( ob_preds_merged )\n",
    "    else:\n",
    "        # Add more dicts to orderbound preds and modify base_preds_flattened\n",
    "        updated_of_preds = merge_preds_ordered( base_preds, orfs_dict[i] )\n",
    "        base_preds_flattened =  flatten( updated_of_preds )\n",
    "        base_preds = updated_of_preds\n",
    "    \n",
    "    \n",
    "    # Classification report\n",
    "    cr_order_bound_coarse = classification_report( picos_coarse, base_preds_flattened, digits=4  )\n",
    "    print(f'Confusion matrix for coarse-grained ground truth and {i} matches')\n",
    "    print( cr_order_bound_coarse )\n",
    "\n",
    "    cr_order_bound_fine = classification_report( picos_fine, base_preds_flattened, digits=4  )\n",
    "    print(f'\\n\\nConfusion matrix for fine-grained ground truth and {i} matches')\n",
    "    print( cr_order_bound_fine )\n",
    "    \n",
    "    print( '--------------------------------------------------------------------------' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b5d0f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376cf42e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d25b21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
