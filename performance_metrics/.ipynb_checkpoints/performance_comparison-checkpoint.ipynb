{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c52d877",
   "metadata": {},
   "source": [
    "# Compare performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54f3d5fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-f0cb3b2954f1>:12: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.*` instead of `tqdm._tqdm_notebook.*`\n",
      "  from tqdm._tqdm_notebook import tqdm_notebook\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import ast\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Sklearn imports\n",
    "from sklearn.metrics import f1_score, recall_score\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, auc, roc_curve\n",
    "\n",
    "from tqdm import tqdm\n",
    "from tqdm._tqdm_notebook import tqdm_notebook\n",
    "tqdm_notebook.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72cc22ec",
   "metadata": {},
   "source": [
    "## utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74b4f9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(d):\n",
    "    l = [ v for k,v in d.items() ]\n",
    "    l = [item for sublist in l for item in sublist]\n",
    "    l = list(map(int, l))\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd2c016f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarize_fine(l):\n",
    "    binarized_labels = []\n",
    "    \n",
    "    for i in l:\n",
    "        if i > 1:\n",
    "            i = 1\n",
    "            binarized_labels.append( i )\n",
    "        else:\n",
    "            binarized_labels.append( i )\n",
    "    \n",
    "    return binarized_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1707b6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def are_n_consecutive(numbers, n):\n",
    "    n = 2\n",
    "    if len(numbers) < n:\n",
    "        return False\n",
    "    for i in range(len(numbers) - n + 1):\n",
    "        window = numbers[i:i+n]\n",
    "        if max(window) - min(window) != n-1:\n",
    "            continue\n",
    "        if len(set(window)) == n:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8e7981c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_order():\n",
    "    \n",
    "    order = ['lf_Professional_Society.tsv',\n",
    "    'lf_Biomedical_Occupation_or_Discipline.tsv',\n",
    "    'lf_Idea_or_Concept.tsv',\n",
    "    'lf_Classification.tsv',\n",
    "    'lf_Biomedical_or_Dental_Material.tsv',\n",
    "    'lf_Manufactured_Object.tsv',\n",
    "    'lf_Functional_Concept.tsv',\n",
    "    'lf_Temporal_Concept.tsv',\n",
    "    'lf_Gene_or_Genome.tsv',\n",
    "    'lf_Organic_Chemical.tsv',\n",
    "    'lf_Biologically_Active_Substance.tsv',\n",
    "    'lf_Medical_Device.tsv',\n",
    "    'lf_Pharmacologic_Substance.tsv',\n",
    "    'lf_Intellectual_Product.tsv',\n",
    "    'lf_Diagnostic_Procedure.tsv',\n",
    "    'lf_Laboratory_Procedure.tsv',\n",
    "    'lf_Health_Care_Activity.tsv',\n",
    "    'lf_Therapeutic_or_Preventive_Procedure.tsv',\n",
    "    'lf_Finding.tsv']\n",
    "    \n",
    "    \n",
    "    return order"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb20cfa",
   "metadata": {},
   "source": [
    "## groundtruth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3d60837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load groundtruth for coarse matches\n",
    "\n",
    "gt_file = '/mnt/nas2/results/Results/systematicReview/order_free_matching/EBM_PICO_training_matches/order_bound/lf_Therapeutic_or_Preventive_Procedure.tsv'\n",
    "\n",
    "# open file and load into a dataframe\n",
    "groundtruth_df = pd.read_csv(gt_file, sep='\\t', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57d66f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process the coarse and fine and add the pmid:gt to a ob dictionaries\n",
    "gt_coarse = dict()\n",
    "gt_fine = dict()\n",
    "\n",
    "for identifier, x, y in zip(groundtruth_df['pmid'], groundtruth_df['i'], groundtruth_df['i_f']):\n",
    "    x = ast.literal_eval(x)\n",
    "    y = ast.literal_eval(y)\n",
    "    \n",
    "    gt_coarse[str(identifier)] = x\n",
    "    gt_fine[str(identifier)] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64b62c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of PMIDs for groundtruth - coarse:  4802\n",
      "Total number of PMIDs for groundtruth - fine:  4802\n"
     ]
    }
   ],
   "source": [
    "print( 'Total number of PMIDs for groundtruth - coarse: ', len(gt_coarse) )\n",
    "print( 'Total number of PMIDs for groundtruth - fine: ', len(gt_fine) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50995d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten groundtruth\n",
    "\n",
    "gt_coarse_flattened = flatten( gt_coarse )\n",
    "gt_fine_flattened = flatten( gt_fine )\n",
    "\n",
    "# binarize the fine groundtruth labels\n",
    "gt_fine_flattened = binarize_fine(gt_fine_flattened)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d0e019",
   "metadata": {},
   "source": [
    "## order-bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6c33b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_order = get_order()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "090307dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load order bound matches for all dictionaries\n",
    "\n",
    "ob_dir = '/mnt/nas2/results/Results/systematicReview/order_free_matching/EBM_PICO_training_matches/order_bound'\n",
    "ob_files = os.listdir(ob_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee7fdf68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/19 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lf_Professional_Society.tsv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▌         | 1/19 [00:03<00:55,  3.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lf_Biomedical_Occupation_or_Discipline.tsv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|█         | 2/19 [00:06<00:51,  3.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lf_Idea_or_Concept.tsv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█▌        | 3/19 [00:09<00:48,  3.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lf_Classification.tsv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|██        | 4/19 [00:12<00:45,  3.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lf_Biomedical_or_Dental_Material.tsv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|██▋       | 5/19 [00:15<00:41,  2.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lf_Manufactured_Object.tsv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|███▏      | 6/19 [00:18<00:38,  3.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lf_Functional_Concept.tsv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|███▋      | 7/19 [00:21<00:36,  3.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lf_Temporal_Concept.tsv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|████▏     | 8/19 [00:24<00:33,  3.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lf_Gene_or_Genome.tsv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|████▋     | 9/19 [00:27<00:30,  3.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lf_Organic_Chemical.tsv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|█████▎    | 10/19 [00:30<00:27,  3.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lf_Biologically_Active_Substance.tsv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|█████▊    | 11/19 [00:33<00:24,  3.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lf_Medical_Device.tsv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|██████▎   | 12/19 [00:36<00:21,  3.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lf_Pharmacologic_Substance.tsv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|██████▊   | 13/19 [00:40<00:19,  3.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lf_Intellectual_Product.tsv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|███████▎  | 14/19 [00:43<00:15,  3.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lf_Diagnostic_Procedure.tsv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 79%|███████▉  | 15/19 [00:46<00:12,  3.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lf_Laboratory_Procedure.tsv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|████████▍ | 16/19 [00:49<00:09,  3.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lf_Health_Care_Activity.tsv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 89%|████████▉ | 17/19 [00:53<00:06,  3.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lf_Therapeutic_or_Preventive_Procedure.tsv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|█████████▍| 18/19 [00:55<00:02,  2.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lf_Finding.tsv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:58<00:00,  3.10s/it]\n"
     ]
    }
   ],
   "source": [
    "ob_matches = dict()\n",
    "\n",
    "for i in tqdm(in_order):\n",
    "    print(i)\n",
    "    file_path = f'{ob_dir}/{i}'\n",
    "    \n",
    "    filename = str(i).replace('lf_', '')\n",
    "    filename = str(filename).replace('.tsv', '')\n",
    "    \n",
    "    # open file and load into a dataframe\n",
    "    data_df = pd.read_csv(file_path, sep='\\t', header=0)\n",
    "    \n",
    "    # process the labels and add the pmid:labels to a ob dictionary\n",
    "    labs_all = []\n",
    "    for x in data_df['labels']:\n",
    "        x = ast.literal_eval(x)\n",
    "        labs_all.append( x )\n",
    "    ob_matches[filename] = dict( zip( data_df['pmid'],  pd.Series( labs_all )) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e487c44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of PMIDs for orderbound files:  4802\n"
     ]
    }
   ],
   "source": [
    "print( 'Total number of PMIDs for orderbound files: ', len(ob_matches['Therapeutic_or_Preventive_Procedure']) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "19b9cc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(gt_fine) == len( ob_matches['Therapeutic_or_Preventive_Procedure'] ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e72f5e63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4802"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gt_fine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "faf4f66c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix for coarse-grained ground truth and Professional_Society matches\n",
      "0.5000, 0.4746, 0.9033, 1.0000, 0.9492, 0.2000, 0.0000, 0.0000\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and Professional_Society matches\n",
      "0.5000, 0.4821, 0.9307, 1.0000, 0.9641, 0.0000, 0.0000, 0.0000\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and Biomedical_Occupation_or_Discipline matches\n",
      "0.5025, 0.4826, 0.9038, 0.9958, 0.9476, 0.1906, 0.0093, 0.0177\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and Biomedical_Occupation_or_Discipline matches\n",
      "0.5038, 0.4922, 0.9312, 0.9958, 0.9624, 0.1730, 0.0118, 0.0221\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and Idea_or_Concept matches\n",
      "0.4853, 0.4824, 0.9006, 0.9249, 0.9126, 0.0610, 0.0456, 0.0522\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and Idea_or_Concept matches\n",
      "0.4855, 0.4858, 0.9287, 0.9257, 0.9272, 0.0434, 0.0453, 0.0443\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and Classification matches\n",
      "0.4984, 0.4826, 0.9031, 0.9827, 0.9412, 0.0805, 0.0141, 0.0240\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and Classification matches\n",
      "0.4981, 0.4887, 0.9305, 0.9828, 0.9559, 0.0545, 0.0133, 0.0214\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and Biomedical_or_Dental_Material matches\n",
      "0.5136, 0.5043, 0.9057, 0.9940, 0.9478, 0.3721, 0.0331, 0.0608\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and Biomedical_or_Dental_Material matches\n",
      "0.5167, 0.5165, 0.9329, 0.9937, 0.9624, 0.3202, 0.0397, 0.0707\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and Manufactured_Object matches\n",
      "0.5038, 0.4921, 0.9040, 0.9821, 0.9414, 0.1320, 0.0254, 0.0427\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and Manufactured_Object matches\n",
      "0.5061, 0.5018, 0.9315, 0.9822, 0.9562, 0.1117, 0.0300, 0.0474\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and Functional_Concept matches\n",
      "0.5017, 0.5016, 0.9037, 0.8972, 0.9004, 0.0995, 0.1062, 0.1028\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and Functional_Concept matches\n",
      "0.5071, 0.5040, 0.9318, 0.8979, 0.9145, 0.0781, 0.1163, 0.0935\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and Temporal_Concept matches\n",
      "0.5009, 0.4955, 0.9035, 0.9581, 0.9300, 0.1006, 0.0438, 0.0610\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and Temporal_Concept matches\n",
      "0.5012, 0.4998, 0.9309, 0.9581, 0.9443, 0.0731, 0.0444, 0.0552\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and Gene_or_Genome matches\n",
      "0.5056, 0.4906, 0.9043, 0.9921, 0.9462, 0.2051, 0.0192, 0.0351\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and Gene_or_Genome matches\n",
      "0.5078, 0.5013, 0.9317, 0.9920, 0.9610, 0.1804, 0.0235, 0.0416\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and Organic_Chemical matches\n",
      "0.5577, 0.5757, 0.9137, 0.9820, 0.9466, 0.4416, 0.1334, 0.2049\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and Organic_Chemical matches\n",
      "0.5750, 0.5989, 0.9407, 0.9812, 0.9605, 0.4003, 0.1687, 0.2374\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and Biologically_Active_Substance matches\n",
      "0.5072, 0.4925, 0.9046, 0.9940, 0.9472, 0.2676, 0.0204, 0.0378\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and Biologically_Active_Substance matches\n",
      "0.5094, 0.5034, 0.9320, 0.9939, 0.9620, 0.2339, 0.0248, 0.0449\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and Medical_Device matches\n",
      "0.5084, 0.4959, 0.9048, 0.9917, 0.9463, 0.2454, 0.0251, 0.0455\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and Medical_Device matches\n",
      "0.5108, 0.5067, 0.9321, 0.9916, 0.9610, 0.2103, 0.0300, 0.0525\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and Pharmacologic_Substance matches\n",
      "0.5715, 0.5919, 0.9163, 0.9742, 0.9444, 0.4122, 0.1688, 0.2395\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and Pharmacologic_Substance matches\n",
      "0.5927, 0.6140, 0.9432, 0.9733, 0.9580, 0.3714, 0.2122, 0.2701\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and Intellectual_Product matches\n",
      "0.4837, 0.4845, 0.9001, 0.8708, 0.8852, 0.0741, 0.0966, 0.0838\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and Intellectual_Product matches\n",
      "0.4871, 0.4860, 0.9288, 0.8721, 0.8996, 0.0560, 0.1020, 0.0723\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and Diagnostic_Procedure matches\n",
      "0.5024, 0.4871, 0.9038, 0.9877, 0.9439, 0.1302, 0.0171, 0.0303\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and Diagnostic_Procedure matches\n",
      "0.5037, 0.4960, 0.9312, 0.9878, 0.9587, 0.1072, 0.0197, 0.0333\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and Laboratory_Procedure matches\n",
      "0.5155, 0.5110, 0.9061, 0.9841, 0.9435, 0.2400, 0.0469, 0.0785\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and Laboratory_Procedure matches\n",
      "0.5207, 0.5241, 0.9335, 0.9840, 0.9580, 0.2105, 0.0574, 0.0903\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and Health_Care_Activity matches\n",
      "0.5077, 0.5028, 0.9047, 0.9682, 0.9354, 0.1371, 0.0472, 0.0702\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and Health_Care_Activity matches\n",
      "0.5101, 0.5101, 0.9321, 0.9681, 0.9498, 0.1085, 0.0522, 0.0705\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and Therapeutic_or_Preventive_Procedure matches\n",
      "0.5460, 0.5563, 0.9117, 0.9656, 0.9379, 0.2821, 0.1265, 0.1747\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and Therapeutic_or_Preventive_Procedure matches\n",
      "0.5588, 0.5698, 0.9387, 0.9648, 0.9516, 0.2443, 0.1529, 0.1881\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and Finding matches\n",
      "0.4802, 0.4800, 0.8992, 0.8351, 0.8660, 0.0752, 0.1254, 0.0940\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and Finding matches\n",
      "0.4851, 0.4802, 0.9284, 0.8368, 0.8803, 0.0573, 0.1334, 0.0802\n",
      "--------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# calculate performance metrics for order-bound files\n",
    "\n",
    "for k, v in ob_matches.items():\n",
    "    \n",
    "    v_flattened = flatten( v )\n",
    "    \n",
    "    # Classification report\n",
    "    cr_order_bound_coarse = classification_report( gt_coarse_flattened, v_flattened, digits=4, output_dict=True)\n",
    "    print(f'Confusion matrix for coarse-grained ground truth and {k} matches')\n",
    "    report = '{:.4f}, {:.4f}, {:.4f}, {:.4f}, {:.4f}, {:.4f}, {:.4f}, {:.4f}'.format(cr_order_bound_coarse['macro avg']['recall'], cr_order_bound_coarse['macro avg']['f1-score'], cr_order_bound_coarse['0']['precision'], cr_order_bound_coarse['0']['recall'], cr_order_bound_coarse['0']['f1-score'], cr_order_bound_coarse['1']['precision'], cr_order_bound_coarse['1']['recall'], cr_order_bound_coarse['1']['f1-score'])\n",
    "    print( report )\n",
    "    \n",
    "\n",
    "    cr_order_bound_fine = classification_report( gt_fine_flattened, v_flattened, digits=4, output_dict=True)\n",
    "    print(f'\\n\\nConfusion matrix for fine-grained ground truth and {k} matches')\n",
    "    report = '{:.4f}, {:.4f}, {:.4f}, {:.4f}, {:.4f}, {:.4f}, {:.4f}, {:.4f}'.format(cr_order_bound_fine['macro avg']['recall'], cr_order_bound_fine['macro avg']['f1-score'], cr_order_bound_fine['0']['precision'], cr_order_bound_fine['0']['recall'], cr_order_bound_fine['0']['f1-score'], cr_order_bound_fine['1']['precision'], cr_order_bound_fine['1']['recall'], cr_order_bound_fine['1']['f1-score'])\n",
    "    print( report )\n",
    "    \n",
    "    print( '--------------------------------------------------------------------------' )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82e2513",
   "metadata": {},
   "source": [
    "## order-free"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "42b3a433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load order free matches with all dictionaries\n",
    "\n",
    "picos = 'I' # ['P', 'I', 'O', 'S']\n",
    "match_level = 'doc' # ['doc', 'sent', 'win_5', 'para']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c76d69ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files:  ['Biomedical_or_Dental_Material.json', '.nfs0000000011200a4200000003', 'Classification.json', 'Intellectual_Product.json', 'Biologically_Active_Substance.json', 'Diagnostic_Procedure.json', 'Gene_or_Genome.json', 'Finding.json', 'Functional_Concept.json', 'Medical_Device.json', 'Organic_Chemical.json', 'Laboratory__Procedure.json', 'Manufactured_Object.json', 'train_ebm_intervention.json', 'Professional_Society.json', 'Pharmacologic_Substance.json', 'Therapeutic_or_Preventive_Procedure.json', 'train_ebm_intervention_syn.json', 'Biomedical_Occupation_or_Discipline.json', 'Health_Care_Activity.json', 'Idea_or_Concept.json', 'Temporal_Concept.json']\n"
     ]
    }
   ],
   "source": [
    "order_free_dir = f'/mnt/nas2/results/Results/systematicReview/order_free_matching/EBM_PICO_training_matches/order_free/{match_level}/{picos}'\n",
    "order_free_files = os.listdir(order_free_dir)\n",
    "print('Files: ', order_free_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d7c54024",
   "metadata": {},
   "outputs": [],
   "source": [
    "order_free_files.remove('.nfs0000000011200a4200000003')\n",
    "#order_free_files.remove('Finding.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "583e8df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file... Biomedical_or_Dental_Material.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▍         | 1/21 [00:02<00:40,  2.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file... Classification.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|▉         | 2/21 [00:03<00:30,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file... Intellectual_Product.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|█▍        | 3/21 [00:25<03:14, 10.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file... Biologically_Active_Substance.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|█▉        | 4/21 [00:30<02:28,  8.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file... Diagnostic_Procedure.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██▍       | 5/21 [00:55<03:55, 14.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file... Gene_or_Genome.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|██▊       | 6/21 [00:57<02:32, 10.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file... Finding.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 7/21 [02:42<09:38, 41.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file... Functional_Concept.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 8/21 [02:43<06:09, 28.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file... Medical_Device.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|████▎     | 9/21 [02:47<04:09, 20.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file... Organic_Chemical.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|████▊     | 10/21 [03:14<04:09, 22.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file... Laboratory__Procedure.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████▏    | 11/21 [03:29<03:24, 20.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file... Manufactured_Object.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|█████▋    | 12/21 [03:30<02:09, 14.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file... train_ebm_intervention.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▏   | 13/21 [03:44<01:54, 14.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file... Professional_Society.json\n",
      "Loading file... Pharmacologic_Substance.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|███████▏  | 15/21 [04:16<01:30, 15.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file... Therapeutic_or_Preventive_Procedure.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|███████▌  | 16/21 [08:37<06:21, 76.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file... train_ebm_intervention_syn.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 18/21 [08:41<02:05, 41.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file... Biomedical_Occupation_or_Discipline.json\n",
      "Loading file... Health_Care_Activity.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 19/21 [09:01<01:11, 35.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file... Idea_or_Concept.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|█████████▌| 20/21 [09:01<00:25, 25.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file... Temporal_Concept.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [09:02<00:00, 25.84s/it]\n"
     ]
    }
   ],
   "source": [
    "orf_loaded_files = dict()\n",
    "\n",
    "for i in tqdm(order_free_files):\n",
    "    \n",
    "    filpath = f'{order_free_dir}/{i}'\n",
    "    print('Loading file...', i)\n",
    "    with open( filpath, 'r' ) as rf:\n",
    "        orf_i = json.load(rf)\n",
    "        orf_loaded_files[i] = orf_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ffb11b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set variables\n",
    "\n",
    "set_partial_matches = False\n",
    "set_actual_orf_matches = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "566f56f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_orf(v, par, actual_orf):\n",
    "    \n",
    "    orfs = dict()\n",
    "    \n",
    "    for k_i, v_i in v.items():\n",
    "        # print( k_i ) # example: name_15_3, name_9_9, name_12_8\n",
    "        \n",
    "        if 'Inters. (full)' in v_i and len(v_i['Inters. (full)']) > 0:\n",
    "            \n",
    "            full_inters = v_i['Inters. (full)']\n",
    "            # full_inters.keys() = PMIDs\n",
    "            # full_inters.values() = offsets, tokens\n",
    "\n",
    "            for pmid, matches in full_inters.items():\n",
    "                if len(matches['char offs.']) > 1:\n",
    "                    if pmid not in orfs:\n",
    "                        if actual_orf == True:\n",
    "                            #if sorted( matches['word offs.'] ) != matches['word offs.']:\n",
    "                            if are_n_consecutive(matches['word offs.'], 2) == False:\n",
    "                                orfs[pmid] = [ ]\n",
    "                                orfs[pmid].extend( matches['word offs.'] )      \n",
    "                        elif actual_orf == False: \n",
    "                            orfs[pmid] = [ ]\n",
    "                            orfs[pmid].extend( matches['word offs.'] )\n",
    "                    else:\n",
    "                        if actual_orf == True:\n",
    "                            #if sorted( matches['word offs.'] ) != matches['word offs.']:\n",
    "                            if are_n_consecutive(matches['word offs.'], 2) == False:\n",
    "                                orfs[pmid].extend( matches['word offs.'] )\n",
    "                        elif actual_orf == False:\n",
    "                            orfs[pmid].extend( matches['word offs.'] )\n",
    "\n",
    "\n",
    "        if 'Inters. (partial)' in v_i and len(v_i['Inters. (partial)']) > 0 and (par=='both' or par==True):\n",
    "            \n",
    "            par_inters = v_i['Inters. (partial)']\n",
    "            \n",
    "            for pmid, matches in par_inters.items():\n",
    "                if len(matches['char offs.']) > 1:\n",
    "                    if pmid not in orfs:\n",
    "                        if actual_orf == True:\n",
    "                            #if sorted( matches['word offs.'] ) != matches['word offs.']:\n",
    "                            if are_n_consecutive(matches['word offs.'], 2) == False:\n",
    "                                orfs[pmid] = [ ]\n",
    "                                orfs[pmid].extend( matches['word offs.'] )   \n",
    "                        elif actual_orf == False:\n",
    "                            orfs[pmid] = [ ]\n",
    "                            orfs[pmid].extend( matches['word offs.'] ) \n",
    "                    else:\n",
    "                        if actual_orf == True:\n",
    "                            #if sorted( matches['word offs.'] ) != matches['word offs.']:\n",
    "                            if are_n_consecutive(matches['word offs.'], 2) == False:\n",
    "                                orfs[pmid].extend( matches['word offs.'] )\n",
    "                        elif actual_orf == False:\n",
    "                            orfs[pmid].extend( matches['word offs.'] )\n",
    "    \n",
    "    return orfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "6b8bb020",
   "metadata": {},
   "outputs": [],
   "source": [
    "orfs_dict = dict()\n",
    "\n",
    "for k,v in orf_loaded_files.items():\n",
    "    \n",
    "    new_k = str(k).replace('.json', '')\n",
    "\n",
    "    orf_fetched = get_orf(v, par = set_partial_matches, actual_orf = set_actual_orf_matches)\n",
    "    orfs_dict[new_k] = orf_fetched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e4507b7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Offsets in Biomedical_or_Dental_Material:  3258\n",
      "Offsets in Classification:  8369\n",
      "Offsets in Intellectual_Product:  86335\n",
      "Offsets in Biologically_Active_Substance:  15494\n",
      "Offsets in Diagnostic_Procedure:  33795\n",
      "Offsets in Gene_or_Genome:  7226\n",
      "Offsets in Finding:  298450\n",
      "Offsets in Functional_Concept:  19792\n",
      "Offsets in Medical_Device:  10628\n",
      "Offsets in Organic_Chemical:  13818\n",
      "Offsets in Laboratory__Procedure:  44098\n",
      "Offsets in Manufactured_Object:  7624\n",
      "Offsets in train_ebm_intervention:  2835\n",
      "Offsets in Professional_Society:  8\n",
      "Offsets in Pharmacologic_Substance:  37882\n",
      "Offsets in Therapeutic_or_Preventive_Procedure:  145151\n",
      "Offsets in train_ebm_intervention_syn:  25540\n",
      "Offsets in Biomedical_Occupation_or_Discipline:  4425\n",
      "Offsets in Health_Care_Activity:  60790\n",
      "Offsets in Idea_or_Concept:  13321\n",
      "Offsets in Temporal_Concept:  70258\n"
     ]
    }
   ],
   "source": [
    "# Order the loaded ORF matches in ascending order depending on the number of matches found\n",
    "\n",
    "order_offset_dict = dict()\n",
    "\n",
    "for k,v in orfs_dict.items():\n",
    "    \n",
    "    total_offsets = []\n",
    "    for k_i, v_i in v.items():\n",
    "        total_offsets.extend( v_i )\n",
    "    \n",
    "    order_offset_dict[k] = len(total_offsets)\n",
    "    \n",
    "    print( f'Offsets in {k}: ', len(total_offsets) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ad3ec144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort dictionary\n",
    "order_offset_sorteddict = dict(sorted(order_offset_dict.items(), key=lambda x: x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "63956c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of dictionaries loaded:  21\n"
     ]
    }
   ],
   "source": [
    "print( 'Total number of dictionaries loaded: ', len(order_offset_sorteddict) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "710ef7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temporary - to remove\n",
    "del order_offset_sorteddict['train_ebm_intervention_syn']\n",
    "del order_offset_sorteddict['train_ebm_intervention']\n",
    "\n",
    "orfs_dict[\"Laboratory_Procedure\"] = orfs_dict.pop(\"Laboratory__Procedure\")\n",
    "order_offset_sorteddict[\"Laboratory_Procedure\"] = order_offset_sorteddict.pop(\"Laboratory__Procedure\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "1e0c1bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len( order_offset_sorteddict.keys() ) == len( ob_matches.keys() )\n",
    "assert sorted( order_offset_sorteddict.keys() ) == sorted( ob_matches.keys() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e862e821",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Professional_Society',\n",
       " 'Biomedical_or_Dental_Material',\n",
       " 'Biomedical_Occupation_or_Discipline',\n",
       " 'Gene_or_Genome',\n",
       " 'Manufactured_Object',\n",
       " 'Classification',\n",
       " 'Medical_Device',\n",
       " 'Idea_or_Concept',\n",
       " 'Organic_Chemical',\n",
       " 'Biologically_Active_Substance',\n",
       " 'Functional_Concept',\n",
       " 'Diagnostic_Procedure',\n",
       " 'Pharmacologic_Substance',\n",
       " 'Health_Care_Activity',\n",
       " 'Temporal_Concept',\n",
       " 'Intellectual_Product',\n",
       " 'Therapeutic_or_Preventive_Procedure',\n",
       " 'Finding',\n",
       " 'Laboratory_Procedure']"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list( order_offset_sorteddict.keys() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "6120fda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_preds_ordered( ob_preds, orf_offsets ):\n",
    "    \n",
    "    merged_predictions = dict()\n",
    "    \n",
    "    for k, v in ob_preds.items(): # ob preds are the old preds\n",
    "        \n",
    "        k = str(k)\n",
    "\n",
    "        if k in orf_offsets:\n",
    "            matching_offsets = orf_offsets[k]\n",
    "            old_preds = list( map( int, v ))\n",
    "            new_preds = list( map( int, v ))\n",
    "                             \n",
    "            # add new offsets to the new_preds\n",
    "            for indice in matching_offsets:\n",
    "                new_preds[indice] = 1\n",
    "\n",
    "            merged_predictions[ k ] = new_preds\n",
    "        else:\n",
    "            merged_predictions[ k ] = list( map( int, v ) )\n",
    "    \n",
    "    return merged_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d554d554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix for coarse-grained ground truth and lf_Professional_Society.tsv matches\n",
      "0.5000, 0.4746, 0.9033, 1.0000, 0.9492, 0.2105, 0.0000, 0.0001\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and lf_Professional_Society.tsv matches\n",
      "0.5000, 0.4821, 0.9307, 1.0000, 0.9641, 0.0000, 0.0000, 0.0000\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and lf_Biomedical_Occupation_or_Discipline.tsv matches\n",
      "0.5027, 0.4839, 0.9038, 0.9944, 0.9470, 0.1749, 0.0110, 0.0207\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and lf_Biomedical_Occupation_or_Discipline.tsv matches\n",
      "0.5042, 0.4936, 0.9313, 0.9945, 0.9618, 0.1573, 0.0138, 0.0254\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and lf_Idea_or_Concept.tsv matches\n",
      "0.4861, 0.4841, 0.9007, 0.9203, 0.9104, 0.0651, 0.0519, 0.0577\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and lf_Idea_or_Concept.tsv matches\n",
      "0.4870, 0.4875, 0.9289, 0.9212, 0.9250, 0.0475, 0.0528, 0.0500\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and lf_Classification.tsv matches\n",
      "0.4982, 0.4830, 0.9030, 0.9814, 0.9406, 0.0798, 0.0151, 0.0254\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and lf_Classification.tsv matches\n",
      "0.4979, 0.4890, 0.9305, 0.9814, 0.9553, 0.0545, 0.0144, 0.0228\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and lf_Biomedical_or_Dental_Material.tsv matches\n",
      "0.5141, 0.5054, 0.9058, 0.9935, 0.9476, 0.3635, 0.0346, 0.0632\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and lf_Biomedical_or_Dental_Material.tsv matches\n",
      "0.5174, 0.5177, 0.9330, 0.9932, 0.9622, 0.3126, 0.0415, 0.0733\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and lf_Manufactured_Object.tsv matches\n",
      "0.5043, 0.4935, 0.9041, 0.9808, 0.9409, 0.1340, 0.0278, 0.0461\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and lf_Manufactured_Object.tsv matches\n",
      "0.5070, 0.5034, 0.9316, 0.9809, 0.9556, 0.1139, 0.0330, 0.0512\n",
      "--------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# full matches - Order free matches\n",
    "for count, i in enumerate(in_order):\n",
    "    \n",
    "    to_fetch = str(i).replace('lf_', '').replace('.tsv', '')\n",
    "    \n",
    "    base_preds = ob_matches[to_fetch]\n",
    "    base_preds_flattened =  flatten( base_preds )\n",
    "    \n",
    "    updated_of_preds = merge_preds_ordered( base_preds, orfs_dict[to_fetch] )\n",
    "    updated_preds_flattened =  flatten( updated_of_preds )\n",
    "    \n",
    "    # Classification report\n",
    "    cr_order_bound_coarse = classification_report( gt_coarse_flattened, updated_preds_flattened, digits=4, output_dict=True)\n",
    "    print(f'Confusion matrix for coarse-grained ground truth and {i} matches')\n",
    "    report = '{:.4f}, {:.4f}, {:.4f}, {:.4f}, {:.4f}, {:.4f}, {:.4f}, {:.4f}'.format(cr_order_bound_coarse['macro avg']['recall'], cr_order_bound_coarse['macro avg']['f1-score'], cr_order_bound_coarse['0']['precision'], cr_order_bound_coarse['0']['recall'], cr_order_bound_coarse['0']['f1-score'], cr_order_bound_coarse['1']['precision'], cr_order_bound_coarse['1']['recall'], cr_order_bound_coarse['1']['f1-score'])\n",
    "    print( report )\n",
    "\n",
    "    cr_order_bound_fine = classification_report( gt_fine_flattened, updated_preds_flattened, digits=4, output_dict=True)\n",
    "    print(f'\\n\\nConfusion matrix for fine-grained ground truth and {i} matches')\n",
    "    report = '{:.4f}, {:.4f}, {:.4f}, {:.4f}, {:.4f}, {:.4f}, {:.4f}, {:.4f}'.format(cr_order_bound_fine['macro avg']['recall'], cr_order_bound_fine['macro avg']['f1-score'], cr_order_bound_fine['0']['precision'], cr_order_bound_fine['0']['recall'], cr_order_bound_fine['0']['f1-score'], cr_order_bound_fine['1']['precision'], cr_order_bound_fine['1']['recall'], cr_order_bound_fine['1']['f1-score'])\n",
    "    print( report )\n",
    "    \n",
    "    print( '--------------------------------------------------------------------------' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c5ff9757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix for coarse-grained ground truth and lf_Professional_Society.tsv matches\n",
      "0.5000, 0.4750, 0.9033, 0.9993, 0.9489, 0.0862, 0.0006, 0.0012\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and lf_Professional_Society.tsv matches\n",
      "0.5000, 0.4825, 0.9307, 0.9993, 0.9638, 0.0632, 0.0006, 0.0012\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and lf_Biomedical_Occupation_or_Discipline.tsv matches\n",
      "0.5035, 0.4876, 0.9040, 0.9904, 0.9452, 0.1560, 0.0166, 0.0300\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and lf_Biomedical_Occupation_or_Discipline.tsv matches\n",
      "0.5055, 0.4978, 0.9314, 0.9905, 0.9600, 0.1376, 0.0205, 0.0356\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and lf_Idea_or_Concept.tsv matches\n",
      "0.4844, 0.4847, 0.9003, 0.8957, 0.8980, 0.0697, 0.0730, 0.0713\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and lf_Idea_or_Concept.tsv matches\n",
      "0.4864, 0.4871, 0.9288, 0.8969, 0.9125, 0.0519, 0.0759, 0.0617\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and lf_Classification.tsv matches\n",
      "0.4960, 0.4904, 0.9026, 0.9511, 0.9262, 0.0820, 0.0408, 0.0545\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and lf_Classification.tsv matches\n",
      "0.4975, 0.4960, 0.9304, 0.9515, 0.9408, 0.0625, 0.0434, 0.0512\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and lf_Biomedical_or_Dental_Material.tsv matches\n",
      "0.5203, 0.5192, 0.9070, 0.9826, 0.9433, 0.2633, 0.0581, 0.0952\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and lf_Biomedical_or_Dental_Material.tsv matches\n",
      "0.5255, 0.5313, 0.9341, 0.9822, 0.9575, 0.2233, 0.0687, 0.1051\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and lf_Manufactured_Object.tsv matches\n",
      "0.5112, 0.5105, 0.9054, 0.9518, 0.9280, 0.1356, 0.0707, 0.0929\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and lf_Manufactured_Object.tsv matches\n",
      "0.5170, 0.5187, 0.9330, 0.9520, 0.9424, 0.1129, 0.0821, 0.0951\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and lf_Functional_Concept.tsv matches\n",
      "0.4975, 0.4961, 0.9028, 0.8644, 0.8832, 0.0935, 0.1307, 0.1090\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and lf_Functional_Concept.tsv matches\n",
      "0.5040, 0.4969, 0.9313, 0.8654, 0.8972, 0.0730, 0.1425, 0.0966\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and lf_Temporal_Concept.tsv matches\n",
      "0.4960, 0.4955, 0.9026, 0.9161, 0.9093, 0.0883, 0.0759, 0.0816\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and lf_Temporal_Concept.tsv matches\n",
      "0.4976, 0.4974, 0.9304, 0.9166, 0.9234, 0.0655, 0.0786, 0.0714\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and lf_Gene_or_Genome.tsv matches\n",
      "0.5072, 0.5015, 0.9046, 0.9708, 0.9366, 0.1380, 0.0437, 0.0663\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and lf_Gene_or_Genome.tsv matches\n",
      "0.5107, 0.5106, 0.9322, 0.9709, 0.9511, 0.1144, 0.0505, 0.0701\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and lf_Organic_Chemical.tsv matches\n",
      "0.5669, 0.5805, 0.9157, 0.9588, 0.9367, 0.3124, 0.1750, 0.2244\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and lf_Organic_Chemical.tsv matches\n",
      "0.5871, 0.5965, 0.9426, 0.9579, 0.9502, 0.2766, 0.2162, 0.2427\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and lf_Biologically_Active_Substance.tsv matches\n",
      "0.5097, 0.5064, 0.9051, 0.9648, 0.9340, 0.1422, 0.0546, 0.0789\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and lf_Biologically_Active_Substance.tsv matches\n",
      "0.5137, 0.5150, 0.9326, 0.9648, 0.9484, 0.1168, 0.0626, 0.0815\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and lf_Medical_Device.tsv matches\n",
      "0.5203, 0.5209, 0.9072, 0.9143, 0.9107, 0.1361, 0.1263, 0.1310\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and lf_Medical_Device.tsv matches\n",
      "0.5299, 0.5256, 0.9350, 0.9145, 0.9246, 0.1123, 0.1453, 0.1267\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and lf_Pharmacologic_Substance.tsv matches\n",
      "0.5765, 0.5802, 0.9180, 0.9284, 0.9232, 0.2513, 0.2246, 0.2372\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and lf_Pharmacologic_Substance.tsv matches\n",
      "0.6001, 0.5894, 0.9449, 0.9275, 0.9361, 0.2187, 0.2727, 0.2427\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and lf_Intellectual_Product.tsv matches\n",
      "0.4858, 0.4773, 0.9002, 0.7824, 0.8371, 0.0851, 0.1892, 0.1174\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and lf_Intellectual_Product.tsv matches\n",
      "0.4948, 0.4755, 0.9299, 0.7844, 0.8509, 0.0661, 0.2051, 0.1000\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and lf_Diagnostic_Procedure.tsv matches\n",
      "0.5027, 0.5017, 0.9039, 0.8794, 0.8915, 0.1006, 0.1261, 0.1119\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and lf_Diagnostic_Procedure.tsv matches\n",
      "0.5104, 0.5039, 0.9323, 0.8803, 0.9055, 0.0804, 0.1406, 0.1023\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and lf_Laboratory_Procedure.tsv matches\n",
      "0.5129, 0.5115, 0.9059, 0.8876, 0.8967, 0.1163, 0.1382, 0.1263\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and lf_Laboratory_Procedure.tsv matches\n",
      "0.5230, 0.5146, 0.9341, 0.8883, 0.9106, 0.0951, 0.1576, 0.1186\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and lf_Health_Care_Activity.tsv matches\n",
      "0.4958, 0.4835, 0.9024, 0.7822, 0.8380, 0.0933, 0.2093, 0.1290\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and lf_Health_Care_Activity.tsv matches\n",
      "0.5071, 0.4815, 0.9319, 0.7840, 0.8516, 0.0735, 0.2302, 0.1114\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and lf_Therapeutic_or_Preventive_Procedure.tsv matches\n",
      "0.5375, 0.5139, 0.9116, 0.8013, 0.8529, 0.1285, 0.2738, 0.1749\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and lf_Therapeutic_or_Preventive_Procedure.tsv matches\n",
      "0.5575, 0.5115, 0.9401, 0.8020, 0.8656, 0.1052, 0.3130, 0.1575\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and lf_Finding.tsv matches\n",
      "0.4816, 0.4626, 0.8989, 0.7193, 0.7991, 0.0851, 0.2439, 0.1261\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and lf_Finding.tsv matches\n",
      "0.4943, 0.4597, 0.9297, 0.7221, 0.8128, 0.0666, 0.2665, 0.1066\n",
      "--------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# partial matches - order free matches\n",
    "\n",
    "for count, i in enumerate(in_order):\n",
    "    \n",
    "    to_fetch = str(i).replace('lf_', '').replace('.tsv', '')\n",
    "    \n",
    "    base_preds = ob_matches[to_fetch]\n",
    "    base_preds_flattened =  flatten( base_preds )\n",
    "    \n",
    "    updated_of_preds = merge_preds_ordered( base_preds, orfs_dict[to_fetch] )\n",
    "    updated_preds_flattened =  flatten( updated_of_preds )\n",
    "    \n",
    "    # Classification report\n",
    "    cr_order_bound_coarse = classification_report( gt_coarse_flattened, updated_preds_flattened, digits=4, output_dict=True)\n",
    "    print(f'Confusion matrix for coarse-grained ground truth and {i} matches')\n",
    "    report = '{:.4f}, {:.4f}, {:.4f}, {:.4f}, {:.4f}, {:.4f}, {:.4f}, {:.4f}'.format(cr_order_bound_coarse['macro avg']['recall'], cr_order_bound_coarse['macro avg']['f1-score'], cr_order_bound_coarse['0']['precision'], cr_order_bound_coarse['0']['recall'], cr_order_bound_coarse['0']['f1-score'], cr_order_bound_coarse['1']['precision'], cr_order_bound_coarse['1']['recall'], cr_order_bound_coarse['1']['f1-score'])\n",
    "    print( report )\n",
    "\n",
    "    cr_order_bound_fine = classification_report( gt_fine_flattened, updated_preds_flattened, digits=4, output_dict=True)\n",
    "    print(f'\\n\\nConfusion matrix for fine-grained ground truth and {i} matches')\n",
    "    report = '{:.4f}, {:.4f}, {:.4f}, {:.4f}, {:.4f}, {:.4f}, {:.4f}, {:.4f}'.format(cr_order_bound_fine['macro avg']['recall'], cr_order_bound_fine['macro avg']['f1-score'], cr_order_bound_fine['0']['precision'], cr_order_bound_fine['0']['recall'], cr_order_bound_fine['0']['f1-score'], cr_order_bound_fine['1']['precision'], cr_order_bound_fine['1']['recall'], cr_order_bound_fine['1']['f1-score'])\n",
    "    print( report )\n",
    "    \n",
    "    print( '--------------------------------------------------------------------------' )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb59ec9",
   "metadata": {},
   "source": [
    "## actual order-free"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f570f4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load (actualin in in in ) order free matches with all dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "772a99e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix for coarse-grained ground truth and lf_Professional_Society.tsv matches\n",
      "0.5000, 0.4751, 0.9033, 0.9994, 0.9489, 0.0948, 0.0006, 0.0012\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and lf_Professional_Society.tsv matches\n",
      "0.5000, 0.4825, 0.9307, 0.9994, 0.9639, 0.0701, 0.0006, 0.0012\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and lf_Biomedical_Occupation_or_Discipline.tsv matches\n",
      "0.5035, 0.4872, 0.9040, 0.9910, 0.9455, 0.1592, 0.0160, 0.0290\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and lf_Biomedical_Occupation_or_Discipline.tsv matches\n",
      "0.5054, 0.4975, 0.9314, 0.9911, 0.9603, 0.1411, 0.0197, 0.0346\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and lf_Idea_or_Concept.tsv matches\n",
      "0.4847, 0.4849, 0.9004, 0.8971, 0.8987, 0.0700, 0.0724, 0.0711\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and lf_Idea_or_Concept.tsv matches\n",
      "0.4868, 0.4875, 0.9288, 0.8982, 0.9133, 0.0522, 0.0754, 0.0617\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and lf_Classification.tsv matches\n",
      "0.4962, 0.4902, 0.9027, 0.9535, 0.9274, 0.0823, 0.0390, 0.0529\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and lf_Classification.tsv matches\n",
      "0.4976, 0.4959, 0.9304, 0.9539, 0.9420, 0.0626, 0.0414, 0.0498\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and lf_Biomedical_or_Dental_Material.tsv matches\n",
      "0.5193, 0.5174, 0.9068, 0.9830, 0.9433, 0.2588, 0.0555, 0.0914\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and lf_Biomedical_or_Dental_Material.tsv matches\n",
      "0.5240, 0.5292, 0.9339, 0.9826, 0.9576, 0.2187, 0.0655, 0.1008\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and lf_Manufactured_Object.tsv matches\n",
      "0.5106, 0.5094, 0.9053, 0.9539, 0.9290, 0.1351, 0.0672, 0.0898\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and lf_Manufactured_Object.tsv matches\n",
      "0.5160, 0.5177, 0.9329, 0.9541, 0.9434, 0.1123, 0.0780, 0.0920\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and lf_Functional_Concept.tsv matches\n",
      "0.4976, 0.4963, 0.9029, 0.8662, 0.8841, 0.0935, 0.1290, 0.1084\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and lf_Functional_Concept.tsv matches\n",
      "0.5038, 0.4971, 0.9313, 0.8672, 0.8981, 0.0729, 0.1405, 0.0960\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and lf_Temporal_Concept.tsv matches\n",
      "0.4963, 0.4956, 0.9026, 0.9179, 0.9102, 0.0887, 0.0746, 0.0810\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and lf_Temporal_Concept.tsv matches\n",
      "0.4977, 0.4976, 0.9304, 0.9183, 0.9243, 0.0657, 0.0771, 0.0710\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and lf_Gene_or_Genome.tsv matches\n",
      "0.5072, 0.5009, 0.9046, 0.9725, 0.9374, 0.1403, 0.0419, 0.0645\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and lf_Gene_or_Genome.tsv matches\n",
      "0.5105, 0.5101, 0.9321, 0.9726, 0.9519, 0.1159, 0.0483, 0.0682\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and lf_Organic_Chemical.tsv matches\n",
      "0.5654, 0.5792, 0.9154, 0.9600, 0.9372, 0.3139, 0.1709, 0.2213\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and lf_Organic_Chemical.tsv matches\n",
      "0.5852, 0.5953, 0.9423, 0.9592, 0.9507, 0.2780, 0.2111, 0.2400\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and lf_Biologically_Active_Substance.tsv matches\n",
      "0.5094, 0.5057, 0.9051, 0.9670, 0.9350, 0.1439, 0.0519, 0.0763\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and lf_Biologically_Active_Substance.tsv matches\n",
      "0.5132, 0.5143, 0.9325, 0.9670, 0.9494, 0.1182, 0.0595, 0.0791\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and lf_Medical_Device.tsv matches\n",
      "0.5191, 0.5199, 0.9070, 0.9172, 0.9121, 0.1352, 0.1210, 0.1278\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and lf_Medical_Device.tsv matches\n",
      "0.5280, 0.5246, 0.9347, 0.9174, 0.9260, 0.1111, 0.1387, 0.1233\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and lf_Pharmacologic_Substance.tsv matches\n",
      "0.5763, 0.5808, 0.9179, 0.9306, 0.9242, 0.2549, 0.2220, 0.2373\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and lf_Pharmacologic_Substance.tsv matches\n",
      "0.5997, 0.5904, 0.9448, 0.9296, 0.9371, 0.2220, 0.2698, 0.2436\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and lf_Intellectual_Product.tsv matches\n",
      "0.4853, 0.4774, 0.9001, 0.7855, 0.8389, 0.0845, 0.1850, 0.1160\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and lf_Intellectual_Product.tsv matches\n",
      "0.4937, 0.4757, 0.9297, 0.7875, 0.8527, 0.0654, 0.2000, 0.0986\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and lf_Diagnostic_Procedure.tsv matches\n",
      "0.5023, 0.5015, 0.9038, 0.8822, 0.8929, 0.1001, 0.1225, 0.1102\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and lf_Diagnostic_Procedure.tsv matches\n",
      "0.5096, 0.5037, 0.9321, 0.8830, 0.9069, 0.0797, 0.1361, 0.1005\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and lf_Laboratory_Procedure.tsv matches\n",
      "0.5126, 0.5114, 0.9058, 0.8903, 0.8980, 0.1163, 0.1349, 0.1249\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and lf_Laboratory_Procedure.tsv matches\n",
      "0.5222, 0.5146, 0.9340, 0.8909, 0.9119, 0.0948, 0.1534, 0.1172\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and lf_Health_Care_Activity.tsv matches\n",
      "0.4951, 0.4839, 0.9023, 0.7865, 0.8404, 0.0926, 0.2036, 0.1273\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and lf_Health_Care_Activity.tsv matches\n",
      "0.5057, 0.4818, 0.9317, 0.7883, 0.8540, 0.0727, 0.2231, 0.1097\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and lf_Therapeutic_or_Preventive_Procedure.tsv matches\n",
      "0.5366, 0.5141, 0.9114, 0.8045, 0.8546, 0.1282, 0.2687, 0.1736\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and lf_Therapeutic_or_Preventive_Procedure.tsv matches\n",
      "0.5559, 0.5118, 0.9398, 0.8052, 0.8673, 0.1049, 0.3067, 0.1563\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and lf_Finding.tsv matches\n",
      "0.4804, 0.4625, 0.8986, 0.7216, 0.8004, 0.0842, 0.2392, 0.1245\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and lf_Finding.tsv matches\n",
      "0.4925, 0.4596, 0.9294, 0.7243, 0.8141, 0.0657, 0.2606, 0.1050\n",
      "--------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# partial matches - ACTUAL order free matches\n",
    "\n",
    "for count, i in enumerate(in_order):\n",
    "    \n",
    "    to_fetch = str(i).replace('lf_', '').replace('.tsv', '')\n",
    "    \n",
    "    base_preds = ob_matches[to_fetch]\n",
    "    base_preds_flattened =  flatten( base_preds )\n",
    "    \n",
    "    updated_of_preds = merge_preds_ordered( base_preds, orfs_dict[to_fetch] )\n",
    "    updated_preds_flattened =  flatten( updated_of_preds )\n",
    "    \n",
    "    # Classification report\n",
    "    cr_order_bound_coarse = classification_report( gt_coarse_flattened, updated_preds_flattened, digits=4, output_dict=True)\n",
    "    print(f'Confusion matrix for coarse-grained ground truth and {i} matches')\n",
    "    report = '{:.4f}, {:.4f}, {:.4f}, {:.4f}, {:.4f}, {:.4f}, {:.4f}, {:.4f}'.format(cr_order_bound_coarse['macro avg']['recall'], cr_order_bound_coarse['macro avg']['f1-score'], cr_order_bound_coarse['0']['precision'], cr_order_bound_coarse['0']['recall'], cr_order_bound_coarse['0']['f1-score'], cr_order_bound_coarse['1']['precision'], cr_order_bound_coarse['1']['recall'], cr_order_bound_coarse['1']['f1-score'])\n",
    "    print( report )\n",
    "\n",
    "    cr_order_bound_fine = classification_report( gt_fine_flattened, updated_preds_flattened, digits=4, output_dict=True)\n",
    "    print(f'\\n\\nConfusion matrix for fine-grained ground truth and {i} matches')\n",
    "    report = '{:.4f}, {:.4f}, {:.4f}, {:.4f}, {:.4f}, {:.4f}, {:.4f}, {:.4f}'.format(cr_order_bound_fine['macro avg']['recall'], cr_order_bound_fine['macro avg']['f1-score'], cr_order_bound_fine['0']['precision'], cr_order_bound_fine['0']['recall'], cr_order_bound_fine['0']['f1-score'], cr_order_bound_fine['1']['precision'], cr_order_bound_fine['1']['recall'], cr_order_bound_fine['1']['f1-score'])\n",
    "    print( report )\n",
    "    \n",
    "    print( '--------------------------------------------------------------------------' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d685e83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
