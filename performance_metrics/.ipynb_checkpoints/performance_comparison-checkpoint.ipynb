{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db8dc3c9",
   "metadata": {},
   "source": [
    "# Compare performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22b7a2a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-7c20b76cd595>:13: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.*` instead of `tqdm._tqdm_notebook.*`\n",
      "  from tqdm._tqdm_notebook import tqdm_notebook\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import ast\n",
    "import json\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Sklearn imports\n",
    "from sklearn.metrics import f1_score, recall_score\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, auc, roc_curve\n",
    "\n",
    "from tqdm import tqdm\n",
    "from tqdm._tqdm_notebook import tqdm_notebook\n",
    "tqdm_notebook.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5b6ec1",
   "metadata": {},
   "source": [
    "### Set init variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e063ea53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose PICOS entity\n",
    "\n",
    "picos = 'i'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf3d700",
   "metadata": {},
   "source": [
    "## utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee9e1076",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(d):\n",
    "    l = [ v for k,v in d.items() ]\n",
    "    l = [item for sublist in l for item in sublist]\n",
    "    l = list(map(int, l))\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ad2d071",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarize_fine(l):\n",
    "    binarized_labels = []\n",
    "    \n",
    "    for i in l:\n",
    "        if i > 1:\n",
    "            i = 1\n",
    "            binarized_labels.append( i )\n",
    "        else:\n",
    "            binarized_labels.append( i )\n",
    "    \n",
    "    return binarized_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eec528d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def are_n_consecutive(numbers, n):\n",
    "    n = 2\n",
    "    if len(numbers) < n:\n",
    "        return False\n",
    "    for i in range(len(numbers) - n + 1):\n",
    "        window = numbers[i:i+n]\n",
    "        if max(window) - min(window) != n-1:\n",
    "            continue\n",
    "        if len(set(window)) == n:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2022b96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_order():\n",
    "    \n",
    "    order = ['lf_Professional_Society.tsv',\n",
    "    'lf_Biomedical_Occupation_or_Discipline.tsv',\n",
    "    'lf_Idea_or_Concept.tsv',\n",
    "    'lf_Classification.tsv',\n",
    "    'lf_Biomedical_or_Dental_Material.tsv',\n",
    "    'lf_Manufactured_Object.tsv',\n",
    "    'lf_Functional_Concept.tsv',\n",
    "    'lf_Temporal_Concept.tsv',\n",
    "    'lf_Gene_or_Genome.tsv',\n",
    "    'lf_Organic_Chemical.tsv',\n",
    "    'lf_Biologically_Active_Substance.tsv',\n",
    "    'lf_Medical_Device.tsv',\n",
    "    'lf_Pharmacologic_Substance.tsv',\n",
    "    'lf_Intellectual_Product.tsv',\n",
    "    'lf_Diagnostic_Procedure.tsv',\n",
    "    'lf_Laboratory_Procedure.tsv',\n",
    "    'lf_Health_Care_Activity.tsv',\n",
    "    'lf_Therapeutic_or_Preventive_Procedure.tsv',\n",
    "    'lf_Finding.tsv']\n",
    "    \n",
    "    \n",
    "    return order"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4098f4e",
   "metadata": {},
   "source": [
    "## groundtruth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1ca0a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_p_file = '/mnt/nas2/results/Results/systematicReview/order_free_matching/EBM_PICO_training_matches/order_bound/p/lf_Sign_or_Symptom.tsv'\n",
    "gt_i_file = '/mnt/nas2/results/Results/systematicReview/order_free_matching/EBM_PICO_training_matches/order_bound/i/lf_Therapeutic_or_Preventive_Procedure.tsv'\n",
    "gt_o_file = '/mnt/nas2/results/Results/systematicReview/order_free_matching/EBM_PICO_training_matches/order_bound/o/lf_Quantitative_Concept.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "891efa66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load groundtruth for coarse matches\n",
    "\n",
    "if picos == 'p':\n",
    "    gt_file = gt_p_file\n",
    "if picos == 'i':\n",
    "    gt_file = gt_i_file\n",
    "if picos == 'i':\n",
    "    gt_file = gt_o_file\n",
    "\n",
    "# open file and load into a dataframe\n",
    "groundtruth_df = pd.read_csv(gt_file, sep='\\t', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "377fdf34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_gt(picos_x):\n",
    "    # process the coarse and fine and add the pmid:gt to a ob dictionaries\n",
    "    gtcoarse = dict()\n",
    "    gtfine = dict()\n",
    "\n",
    "    for identifier, x, y in zip(groundtruth_df['pmid'], groundtruth_df[picos_x], groundtruth_df[str(picos_x)+'_f']):\n",
    "        x = ast.literal_eval(x)\n",
    "        y = ast.literal_eval(y)\n",
    "\n",
    "        gtcoarse[str(identifier)] = x\n",
    "        gtfine[str(identifier)] = y\n",
    "    \n",
    "    return gtcoarse, gtfine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3666fc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_coarse, gt_fine = preprocess_gt(picos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b638d940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of PMIDs for groundtruth - coarse:  4802\n",
      "Total number of PMIDs for groundtruth - fine:  4802\n"
     ]
    }
   ],
   "source": [
    "print( 'Total number of PMIDs for groundtruth - coarse: ', len(gt_coarse) )\n",
    "print( 'Total number of PMIDs for groundtruth - fine: ', len(gt_fine) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4573661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten groundtruth\n",
    "\n",
    "gt_coarse_flattened = flatten( gt_coarse )\n",
    "gt_fine_flattened = flatten( gt_fine )\n",
    "\n",
    "# binarize the fine groundtruth labels\n",
    "gt_fine_flattened = binarize_fine(gt_fine_flattened)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca85fb1",
   "metadata": {},
   "source": [
    "## order-bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aebfdf32",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_order = get_order()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "20c8f49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load order bound matches for all dictionaries\n",
    "\n",
    "ob_dir = f'/mnt/nas2/results/Results/systematicReview/order_free_matching/EBM_PICO_training_matches/order_bound/{picos}'\n",
    "ob_files = os.listdir(ob_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae45e1a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lf_Medical_Device.tsv',\n",
       " 'lf_Laboratory_Procedure.tsv',\n",
       " 'lf_Manufactured_Object.tsv',\n",
       " 'lf_Pharmacologic_Substance.tsv',\n",
       " 'lf_Diagnostic_Procedure.tsv',\n",
       " 'lf_Therapeutic_or_Preventive_Procedure.tsv',\n",
       " 'lf_Organic_Chemical.tsv',\n",
       " 'lf_Biologically_Active_Substance.tsv',\n",
       " 'lf_Idea_or_Concept.tsv',\n",
       " 'lf_Professional_Society.tsv',\n",
       " 'lf_Temporal_Concept.tsv',\n",
       " 'lf_Finding.tsv',\n",
       " 'lf_Biomedical_or_Dental_Material.tsv',\n",
       " 'lf_Functional_Concept.tsv',\n",
       " 'lf_Biomedical_Occupation_or_Discipline.tsv',\n",
       " 'lf_Gene_or_Genome.tsv',\n",
       " 'lf_Health_Care_Activity.tsv',\n",
       " 'lf_Classification.tsv',\n",
       " 'lf_Intellectual_Product.tsv']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ob_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5274c251",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/19 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lf_Medical_Device.tsv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▌         | 1/19 [00:03<01:07,  3.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lf_Laboratory_Procedure.tsv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|█         | 2/19 [00:07<01:05,  3.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lf_Manufactured_Object.tsv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█▌        | 3/19 [00:11<01:00,  3.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lf_Pharmacologic_Substance.tsv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|██        | 4/19 [00:15<00:57,  3.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lf_Diagnostic_Procedure.tsv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|██▋       | 5/19 [00:18<00:52,  3.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lf_Therapeutic_or_Preventive_Procedure.tsv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|███▏      | 6/19 [00:22<00:49,  3.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lf_Organic_Chemical.tsv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|███▋      | 7/19 [00:26<00:45,  3.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lf_Biologically_Active_Substance.tsv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|████▏     | 8/19 [00:30<00:40,  3.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lf_Idea_or_Concept.tsv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|████▋     | 9/19 [00:33<00:37,  3.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lf_Professional_Society.tsv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|█████▎    | 10/19 [00:37<00:34,  3.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lf_Temporal_Concept.tsv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|█████▊    | 11/19 [00:41<00:30,  3.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lf_Finding.tsv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|██████▎   | 12/19 [00:45<00:27,  3.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lf_Biomedical_or_Dental_Material.tsv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|██████▊   | 13/19 [00:49<00:23,  3.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lf_Functional_Concept.tsv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|███████▎  | 14/19 [00:52<00:18,  3.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lf_Biomedical_Occupation_or_Discipline.tsv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 79%|███████▉  | 15/19 [00:56<00:15,  3.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lf_Gene_or_Genome.tsv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|████████▍ | 16/19 [01:00<00:11,  3.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lf_Health_Care_Activity.tsv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 89%|████████▉ | 17/19 [01:04<00:07,  3.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lf_Classification.tsv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|█████████▍| 18/19 [01:08<00:03,  3.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lf_Intellectual_Product.tsv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [01:12<00:00,  3.80s/it]\n"
     ]
    }
   ],
   "source": [
    "ob_matches = dict()\n",
    "\n",
    "for i in tqdm(ob_files):\n",
    "    print(i)\n",
    "    file_path = f'{ob_dir}/{i}'\n",
    "    \n",
    "    filename = str(i).replace('lf_', '')\n",
    "    filename = str(filename).replace('.tsv', '')\n",
    "    \n",
    "    # open file and load into a dataframe\n",
    "    data_df = pd.read_csv(file_path, sep='\\t', header=0)\n",
    "    \n",
    "    # process the labels and add the pmid:labels to a ob dictionary\n",
    "    labs_all = []\n",
    "    for x in data_df['labels']:\n",
    "        x = ast.literal_eval(x)\n",
    "        labs_all.append( x )\n",
    "    ob_matches[filename] = dict( zip( data_df['pmid'],  pd.Series( labs_all )) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fe8a6162",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_key = random.sample(ob_matches.keys(), 1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "96a2091a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of PMIDs for orderbound files:  4802\n"
     ]
    }
   ],
   "source": [
    "print( 'Total number of PMIDs for orderbound files: ', len(ob_matches[random_key]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f7762f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(gt_fine) == len( ob_matches[random_key] ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3e73ad5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4802"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gt_fine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c3d78912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix for coarse-grained ground truth and Medical_Device matches\n",
      "0.5084, 0.4959, 0.9048, 0.9917, 0.9463, 0.2454, 0.0251, 0.0455\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and Medical_Device matches\n",
      "0.5108, 0.5067, 0.9321, 0.9916, 0.9610, 0.2103, 0.0300, 0.0525\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and Laboratory_Procedure matches\n",
      "0.5155, 0.5110, 0.9061, 0.9841, 0.9435, 0.2400, 0.0469, 0.0785\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and Laboratory_Procedure matches\n",
      "0.5207, 0.5241, 0.9335, 0.9840, 0.9580, 0.2105, 0.0574, 0.0903\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and Manufactured_Object matches\n",
      "0.5038, 0.4921, 0.9040, 0.9821, 0.9414, 0.1320, 0.0254, 0.0427\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and Manufactured_Object matches\n",
      "0.5061, 0.5018, 0.9315, 0.9822, 0.9562, 0.1117, 0.0300, 0.0474\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and Pharmacologic_Substance matches\n",
      "0.5715, 0.5919, 0.9163, 0.9742, 0.9444, 0.4122, 0.1688, 0.2395\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and Pharmacologic_Substance matches\n",
      "0.5927, 0.6140, 0.9432, 0.9733, 0.9580, 0.3714, 0.2122, 0.2701\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and Diagnostic_Procedure matches\n",
      "0.5024, 0.4871, 0.9038, 0.9877, 0.9439, 0.1302, 0.0171, 0.0303\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and Diagnostic_Procedure matches\n",
      "0.5037, 0.4960, 0.9312, 0.9878, 0.9587, 0.1072, 0.0197, 0.0333\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and Therapeutic_or_Preventive_Procedure matches\n",
      "0.5460, 0.5563, 0.9117, 0.9656, 0.9379, 0.2821, 0.1265, 0.1747\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and Therapeutic_or_Preventive_Procedure matches\n",
      "0.5588, 0.5698, 0.9387, 0.9648, 0.9516, 0.2443, 0.1529, 0.1881\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and Organic_Chemical matches\n",
      "0.5577, 0.5757, 0.9137, 0.9820, 0.9466, 0.4416, 0.1334, 0.2049\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and Organic_Chemical matches\n",
      "0.5750, 0.5989, 0.9407, 0.9812, 0.9605, 0.4003, 0.1687, 0.2374\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and Biologically_Active_Substance matches\n",
      "0.5072, 0.4925, 0.9046, 0.9940, 0.9472, 0.2676, 0.0204, 0.0378\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and Biologically_Active_Substance matches\n",
      "0.5094, 0.5034, 0.9320, 0.9939, 0.9620, 0.2339, 0.0248, 0.0449\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and Idea_or_Concept matches\n",
      "0.4853, 0.4824, 0.9006, 0.9249, 0.9126, 0.0610, 0.0456, 0.0522\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and Idea_or_Concept matches\n",
      "0.4855, 0.4858, 0.9287, 0.9257, 0.9272, 0.0434, 0.0453, 0.0443\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and Professional_Society matches\n",
      "0.5000, 0.4746, 0.9033, 1.0000, 0.9492, 0.2000, 0.0000, 0.0000\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and Professional_Society matches\n",
      "0.5000, 0.4821, 0.9307, 1.0000, 0.9641, 0.0000, 0.0000, 0.0000\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and Temporal_Concept matches\n",
      "0.5009, 0.4955, 0.9035, 0.9581, 0.9300, 0.1006, 0.0438, 0.0610\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and Temporal_Concept matches\n",
      "0.5012, 0.4998, 0.9309, 0.9581, 0.9443, 0.0731, 0.0444, 0.0552\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and Finding matches\n",
      "0.4802, 0.4800, 0.8992, 0.8351, 0.8660, 0.0752, 0.1254, 0.0940\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and Finding matches\n",
      "0.4851, 0.4802, 0.9284, 0.8368, 0.8803, 0.0573, 0.1334, 0.0802\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and Biomedical_or_Dental_Material matches\n",
      "0.5136, 0.5043, 0.9057, 0.9940, 0.9478, 0.3721, 0.0331, 0.0608\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and Biomedical_or_Dental_Material matches\n",
      "0.5167, 0.5165, 0.9329, 0.9937, 0.9624, 0.3202, 0.0397, 0.0707\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and Functional_Concept matches\n",
      "0.5017, 0.5016, 0.9037, 0.8972, 0.9004, 0.0995, 0.1062, 0.1028\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and Functional_Concept matches\n",
      "0.5071, 0.5040, 0.9318, 0.8979, 0.9145, 0.0781, 0.1163, 0.0935\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and Biomedical_Occupation_or_Discipline matches\n",
      "0.5025, 0.4826, 0.9038, 0.9958, 0.9476, 0.1906, 0.0093, 0.0177\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and Biomedical_Occupation_or_Discipline matches\n",
      "0.5038, 0.4922, 0.9312, 0.9958, 0.9624, 0.1730, 0.0118, 0.0221\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and Gene_or_Genome matches\n",
      "0.5056, 0.4906, 0.9043, 0.9921, 0.9462, 0.2051, 0.0192, 0.0351\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and Gene_or_Genome matches\n",
      "0.5078, 0.5013, 0.9317, 0.9920, 0.9610, 0.1804, 0.0235, 0.0416\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and Health_Care_Activity matches\n",
      "0.5077, 0.5028, 0.9047, 0.9682, 0.9354, 0.1371, 0.0472, 0.0702\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and Health_Care_Activity matches\n",
      "0.5101, 0.5101, 0.9321, 0.9681, 0.9498, 0.1085, 0.0522, 0.0705\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and Classification matches\n",
      "0.4984, 0.4826, 0.9031, 0.9827, 0.9412, 0.0805, 0.0141, 0.0240\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and Classification matches\n",
      "0.4981, 0.4887, 0.9305, 0.9828, 0.9559, 0.0545, 0.0133, 0.0214\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and Intellectual_Product matches\n",
      "0.4837, 0.4845, 0.9001, 0.8708, 0.8852, 0.0741, 0.0966, 0.0838\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and Intellectual_Product matches\n",
      "0.4871, 0.4860, 0.9288, 0.8721, 0.8996, 0.0560, 0.1020, 0.0723\n",
      "--------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# calculate performance metrics for order-bound files\n",
    "\n",
    "for k, v in ob_matches.items():\n",
    "    \n",
    "    v_flattened = flatten( v )\n",
    "    \n",
    "    # Classification report\n",
    "    cr_order_bound_coarse = classification_report( gt_coarse_flattened, v_flattened, digits=4, output_dict=True)\n",
    "    print(f'Confusion matrix for coarse-grained ground truth and {k} matches')\n",
    "    report = '{:.4f}, {:.4f}, {:.4f}, {:.4f}, {:.4f}, {:.4f}, {:.4f}, {:.4f}'.format(cr_order_bound_coarse['macro avg']['recall'], cr_order_bound_coarse['macro avg']['f1-score'], cr_order_bound_coarse['0']['precision'], cr_order_bound_coarse['0']['recall'], cr_order_bound_coarse['0']['f1-score'], cr_order_bound_coarse['1']['precision'], cr_order_bound_coarse['1']['recall'], cr_order_bound_coarse['1']['f1-score'])\n",
    "    print( report )\n",
    "    \n",
    "\n",
    "    cr_order_bound_fine = classification_report( gt_fine_flattened, v_flattened, digits=4, output_dict=True)\n",
    "    print(f'\\n\\nConfusion matrix for fine-grained ground truth and {k} matches')\n",
    "    report = '{:.4f}, {:.4f}, {:.4f}, {:.4f}, {:.4f}, {:.4f}, {:.4f}, {:.4f}'.format(cr_order_bound_fine['macro avg']['recall'], cr_order_bound_fine['macro avg']['f1-score'], cr_order_bound_fine['0']['precision'], cr_order_bound_fine['0']['recall'], cr_order_bound_fine['0']['f1-score'], cr_order_bound_fine['1']['precision'], cr_order_bound_fine['1']['recall'], cr_order_bound_fine['1']['f1-score'])\n",
    "    print( report )\n",
    "    \n",
    "    print( '--------------------------------------------------------------------------' )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad273152",
   "metadata": {},
   "source": [
    "## order-free"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "03fc8feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load order free matches with all dictionaries\n",
    "\n",
    "picos = 'I' # ['P', 'I', 'O', 'S']\n",
    "match_level = 'doc' # ['doc', 'sent', 'win_5', 'para']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "612d7788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files:  ['Biomedical_or_Dental_Material.json', '.nfs0000000011200a4200000003', 'Classification.json', 'Intellectual_Product.json', 'Biologically_Active_Substance.json', 'Diagnostic_Procedure.json', 'Gene_or_Genome.json', 'Finding.json', 'Functional_Concept.json', 'Medical_Device.json', 'Organic_Chemical.json', 'Laboratory__Procedure.json', 'Manufactured_Object.json', 'train_ebm_intervention.json', 'Professional_Society.json', 'Pharmacologic_Substance.json', 'Therapeutic_or_Preventive_Procedure.json', 'train_ebm_intervention_syn.json', 'Biomedical_Occupation_or_Discipline.json', 'Health_Care_Activity.json', 'Idea_or_Concept.json', 'Temporal_Concept.json']\n"
     ]
    }
   ],
   "source": [
    "order_free_dir = f'/mnt/nas2/results/Results/systematicReview/order_free_matching/EBM_PICO_training_matches/order_free/{match_level}/{picos}'\n",
    "order_free_files = os.listdir(order_free_dir)\n",
    "print('Files: ', order_free_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "16331d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "order_free_files.remove('.nfs0000000011200a4200000003')\n",
    "#order_free_files.remove('Finding.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "022939f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file... Biomedical_or_Dental_Material.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▍         | 1/21 [00:21<07:16, 21.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file... Classification.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|▉         | 2/21 [00:23<03:06,  9.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file... Intellectual_Product.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|█▍        | 3/21 [00:48<05:02, 16.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file... Biologically_Active_Substance.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|█▉        | 4/21 [00:56<03:44, 13.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file... Diagnostic_Procedure.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██▍       | 5/21 [01:27<05:17, 19.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file... Gene_or_Genome.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|██▊       | 6/21 [01:29<03:24, 13.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file... Finding.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 7/21 [03:49<12:49, 54.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file... Functional_Concept.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 8/21 [03:50<08:10, 37.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file... Medical_Device.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|████▎     | 9/21 [03:55<05:30, 27.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file... Organic_Chemical.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|████▊     | 10/21 [04:24<05:08, 28.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file... Laboratory__Procedure.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████▏    | 11/21 [04:43<04:11, 25.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file... Manufactured_Object.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|█████▋    | 12/21 [04:43<02:39, 17.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file... train_ebm_intervention.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▏   | 13/21 [05:02<02:23, 17.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file... Professional_Society.json\n",
      "Loading file... Pharmacologic_Substance.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|███████▏  | 15/21 [05:42<01:53, 18.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file... Therapeutic_or_Preventive_Procedure.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|███████▌  | 16/21 [11:58<08:59, 107.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file... train_ebm_intervention_syn.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 18/21 [12:03<02:56, 58.83s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file... Biomedical_Occupation_or_Discipline.json\n",
      "Loading file... Health_Care_Activity.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 19/21 [12:26<01:37, 48.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file... Idea_or_Concept.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|█████████▌| 20/21 [12:26<00:34, 34.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file... Temporal_Concept.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [12:27<00:00, 35.62s/it]\n"
     ]
    }
   ],
   "source": [
    "orf_loaded_files = dict()\n",
    "\n",
    "for i in tqdm(order_free_files):\n",
    "    \n",
    "    filpath = f'{order_free_dir}/{i}'\n",
    "    print('Loading file...', i)\n",
    "    with open( filpath, 'r' ) as rf:\n",
    "        orf_i = json.load(rf)\n",
    "        orf_loaded_files[i] = orf_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "84d93ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set variables\n",
    "\n",
    "set_partial_matches = True\n",
    "set_actual_orf_matches = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "835016bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_orf(v, par, actual_orf):\n",
    "    \n",
    "    orfs = dict()\n",
    "    \n",
    "    for k_i, v_i in v.items():\n",
    "        # print( k_i ) # example: name_15_3, name_9_9, name_12_8\n",
    "        \n",
    "        if 'Inters. (full)' in v_i and len(v_i['Inters. (full)']) > 0:\n",
    "            \n",
    "            full_inters = v_i['Inters. (full)']\n",
    "            # full_inters.keys() = PMIDs\n",
    "            # full_inters.values() = offsets, tokens\n",
    "\n",
    "            for pmid, matches in full_inters.items():\n",
    "                if len(matches['char offs.']) > 1:\n",
    "                    if pmid not in orfs:\n",
    "                        if actual_orf == True:\n",
    "                            #if sorted( matches['word offs.'] ) != matches['word offs.']:\n",
    "                            if are_n_consecutive(matches['word offs.'], 2) == False:\n",
    "                                orfs[pmid] = [ ]\n",
    "                                orfs[pmid].extend( matches['word offs.'] )      \n",
    "                        elif actual_orf == False: \n",
    "                            orfs[pmid] = [ ]\n",
    "                            orfs[pmid].extend( matches['word offs.'] )\n",
    "                    else:\n",
    "                        if actual_orf == True:\n",
    "                            #if sorted( matches['word offs.'] ) != matches['word offs.']:\n",
    "                            if are_n_consecutive(matches['word offs.'], 2) == False:\n",
    "                                orfs[pmid].extend( matches['word offs.'] )\n",
    "                        elif actual_orf == False:\n",
    "                            orfs[pmid].extend( matches['word offs.'] )\n",
    "\n",
    "\n",
    "        if 'Inters. (partial)' in v_i and len(v_i['Inters. (partial)']) > 0 and (par=='both' or par==True):\n",
    "            \n",
    "            par_inters = v_i['Inters. (partial)']\n",
    "            \n",
    "            for pmid, matches in par_inters.items():\n",
    "                if len(matches['char offs.']) > 1:\n",
    "                    if pmid not in orfs:\n",
    "                        if actual_orf == True:\n",
    "                            #if sorted( matches['word offs.'] ) != matches['word offs.']:\n",
    "                            if are_n_consecutive(matches['word offs.'], 2) == False:\n",
    "                                orfs[pmid] = [ ]\n",
    "                                orfs[pmid].extend( matches['word offs.'] )   \n",
    "                        elif actual_orf == False:\n",
    "                            orfs[pmid] = [ ]\n",
    "                            orfs[pmid].extend( matches['word offs.'] ) \n",
    "                    else:\n",
    "                        if actual_orf == True:\n",
    "                            #if sorted( matches['word offs.'] ) != matches['word offs.']:\n",
    "                            if are_n_consecutive(matches['word offs.'], 2) == False:\n",
    "                                orfs[pmid].extend( matches['word offs.'] )\n",
    "                        elif actual_orf == False:\n",
    "                            orfs[pmid].extend( matches['word offs.'] )\n",
    "    \n",
    "    return orfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ec9f8065",
   "metadata": {},
   "outputs": [],
   "source": [
    "orfs_dict = dict()\n",
    "\n",
    "for k,v in orf_loaded_files.items():\n",
    "    \n",
    "    new_k = str(k).replace('.json', '')\n",
    "\n",
    "    orf_fetched = get_orf(v, par = set_partial_matches, actual_orf = set_actual_orf_matches)\n",
    "    orfs_dict[new_k] = orf_fetched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d750d217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Offsets in Biomedical_or_Dental_Material:  269764\n",
      "Offsets in Classification:  221903\n",
      "Offsets in Intellectual_Product:  6384570\n",
      "Offsets in Biologically_Active_Substance:  1747134\n",
      "Offsets in Diagnostic_Procedure:  8650791\n",
      "Offsets in Gene_or_Genome:  707175\n",
      "Offsets in Finding:  34806379\n",
      "Offsets in Functional_Concept:  438148\n",
      "Offsets in Medical_Device:  2408193\n",
      "Offsets in Organic_Chemical:  1226365\n",
      "Offsets in Laboratory__Procedure:  9350649\n",
      "Offsets in Manufactured_Object:  351652\n",
      "Offsets in train_ebm_intervention:  20569\n",
      "Offsets in Professional_Society:  1014\n",
      "Offsets in Pharmacologic_Substance:  3235747\n",
      "Offsets in Therapeutic_or_Preventive_Procedure:  80134307\n",
      "Offsets in train_ebm_intervention_syn:  74471\n",
      "Offsets in Biomedical_Occupation_or_Discipline:  29481\n",
      "Offsets in Health_Care_Activity:  13611371\n",
      "Offsets in Idea_or_Concept:  168142\n",
      "Offsets in Temporal_Concept:  656504\n"
     ]
    }
   ],
   "source": [
    "# Order the loaded ORF matches in ascending order depending on the number of matches found\n",
    "\n",
    "order_offset_dict = dict()\n",
    "\n",
    "for k,v in orfs_dict.items():\n",
    "    \n",
    "    total_offsets = []\n",
    "    for k_i, v_i in v.items():\n",
    "        total_offsets.extend( v_i )\n",
    "    \n",
    "    order_offset_dict[k] = len(total_offsets)\n",
    "    \n",
    "    print( f'Offsets in {k}: ', len(total_offsets) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8603a35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort dictionary\n",
    "order_offset_sorteddict = dict(sorted(order_offset_dict.items(), key=lambda x: x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7ea19876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of dictionaries loaded:  21\n"
     ]
    }
   ],
   "source": [
    "print( 'Total number of dictionaries loaded: ', len(order_offset_sorteddict) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7cd25acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temporary - to remove\n",
    "del order_offset_sorteddict['train_ebm_intervention_syn']\n",
    "del order_offset_sorteddict['train_ebm_intervention']\n",
    "\n",
    "orfs_dict[\"Laboratory_Procedure\"] = orfs_dict.pop(\"Laboratory__Procedure\")\n",
    "order_offset_sorteddict[\"Laboratory_Procedure\"] = order_offset_sorteddict.pop(\"Laboratory__Procedure\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a8426e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len( order_offset_sorteddict.keys() ) == len( ob_matches.keys() )\n",
    "assert sorted( order_offset_sorteddict.keys() ) == sorted( ob_matches.keys() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1f1e76ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Professional_Society',\n",
       " 'Biomedical_Occupation_or_Discipline',\n",
       " 'Idea_or_Concept',\n",
       " 'Classification',\n",
       " 'Biomedical_or_Dental_Material',\n",
       " 'Manufactured_Object',\n",
       " 'Functional_Concept',\n",
       " 'Temporal_Concept',\n",
       " 'Gene_or_Genome',\n",
       " 'Organic_Chemical',\n",
       " 'Biologically_Active_Substance',\n",
       " 'Medical_Device',\n",
       " 'Pharmacologic_Substance',\n",
       " 'Intellectual_Product',\n",
       " 'Diagnostic_Procedure',\n",
       " 'Health_Care_Activity',\n",
       " 'Finding',\n",
       " 'Therapeutic_or_Preventive_Procedure',\n",
       " 'Laboratory_Procedure']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list( order_offset_sorteddict.keys() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1f231d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_preds_ordered( ob_preds, orf_offsets ):\n",
    "    \n",
    "    merged_predictions = dict()\n",
    "    \n",
    "    for k, v in ob_preds.items(): # ob preds are the old preds\n",
    "        \n",
    "        k = str(k)\n",
    "\n",
    "        if k in orf_offsets:\n",
    "            matching_offsets = orf_offsets[k]\n",
    "            old_preds = list( map( int, v ))\n",
    "            new_preds = list( map( int, v ))\n",
    "                             \n",
    "            # add new offsets to the new_preds\n",
    "            for indice in matching_offsets:\n",
    "                new_preds[indice] = 1\n",
    "\n",
    "            merged_predictions[ k ] = new_preds\n",
    "        else:\n",
    "            merged_predictions[ k ] = list( map( int, v ) )\n",
    "    \n",
    "    return merged_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "85443795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix for coarse-grained ground truth and lf_Professional_Society.tsv matches\n",
      "0.5000, 0.4751, 0.9033, 0.9994, 0.9489, 0.0948, 0.0006, 0.0012\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and lf_Professional_Society.tsv matches\n",
      "0.5000, 0.4825, 0.9307, 0.9994, 0.9639, 0.0701, 0.0006, 0.0012\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and lf_Biomedical_Occupation_or_Discipline.tsv matches\n",
      "0.5035, 0.4872, 0.9040, 0.9910, 0.9455, 0.1592, 0.0160, 0.0290\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and lf_Biomedical_Occupation_or_Discipline.tsv matches\n",
      "0.5054, 0.4975, 0.9314, 0.9911, 0.9603, 0.1411, 0.0197, 0.0346\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and lf_Idea_or_Concept.tsv matches\n",
      "0.4847, 0.4849, 0.9004, 0.8971, 0.8987, 0.0700, 0.0724, 0.0711\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and lf_Idea_or_Concept.tsv matches\n",
      "0.4868, 0.4875, 0.9288, 0.8982, 0.9133, 0.0522, 0.0754, 0.0617\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and lf_Classification.tsv matches\n",
      "0.4962, 0.4902, 0.9027, 0.9535, 0.9274, 0.0823, 0.0390, 0.0529\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and lf_Classification.tsv matches\n",
      "0.4976, 0.4959, 0.9304, 0.9539, 0.9420, 0.0626, 0.0414, 0.0498\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and lf_Biomedical_or_Dental_Material.tsv matches\n",
      "0.5193, 0.5174, 0.9068, 0.9830, 0.9433, 0.2588, 0.0555, 0.0914\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and lf_Biomedical_or_Dental_Material.tsv matches\n",
      "0.5240, 0.5292, 0.9339, 0.9826, 0.9576, 0.2187, 0.0655, 0.1008\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and lf_Manufactured_Object.tsv matches\n",
      "0.5106, 0.5094, 0.9053, 0.9539, 0.9290, 0.1351, 0.0672, 0.0898\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and lf_Manufactured_Object.tsv matches\n",
      "0.5160, 0.5177, 0.9329, 0.9541, 0.9434, 0.1123, 0.0780, 0.0920\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and lf_Functional_Concept.tsv matches\n",
      "0.4976, 0.4963, 0.9029, 0.8662, 0.8841, 0.0935, 0.1290, 0.1084\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and lf_Functional_Concept.tsv matches\n",
      "0.5038, 0.4971, 0.9313, 0.8672, 0.8981, 0.0729, 0.1405, 0.0960\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and lf_Temporal_Concept.tsv matches\n",
      "0.4963, 0.4956, 0.9026, 0.9179, 0.9102, 0.0887, 0.0746, 0.0810\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and lf_Temporal_Concept.tsv matches\n",
      "0.4977, 0.4976, 0.9304, 0.9183, 0.9243, 0.0657, 0.0771, 0.0710\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and lf_Gene_or_Genome.tsv matches\n",
      "0.5072, 0.5009, 0.9046, 0.9725, 0.9374, 0.1403, 0.0419, 0.0645\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and lf_Gene_or_Genome.tsv matches\n",
      "0.5105, 0.5101, 0.9321, 0.9726, 0.9519, 0.1159, 0.0483, 0.0682\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and lf_Organic_Chemical.tsv matches\n",
      "0.5654, 0.5792, 0.9154, 0.9600, 0.9372, 0.3139, 0.1709, 0.2213\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and lf_Organic_Chemical.tsv matches\n",
      "0.5852, 0.5953, 0.9423, 0.9592, 0.9507, 0.2780, 0.2111, 0.2400\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and lf_Biologically_Active_Substance.tsv matches\n",
      "0.5094, 0.5057, 0.9051, 0.9670, 0.9350, 0.1439, 0.0519, 0.0763\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and lf_Biologically_Active_Substance.tsv matches\n",
      "0.5132, 0.5143, 0.9325, 0.9670, 0.9494, 0.1182, 0.0595, 0.0791\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and lf_Medical_Device.tsv matches\n",
      "0.5191, 0.5199, 0.9070, 0.9172, 0.9121, 0.1352, 0.1210, 0.1278\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and lf_Medical_Device.tsv matches\n",
      "0.5280, 0.5246, 0.9347, 0.9174, 0.9260, 0.1111, 0.1387, 0.1233\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and lf_Pharmacologic_Substance.tsv matches\n",
      "0.5763, 0.5808, 0.9179, 0.9306, 0.9242, 0.2549, 0.2220, 0.2373\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and lf_Pharmacologic_Substance.tsv matches\n",
      "0.5997, 0.5904, 0.9448, 0.9296, 0.9371, 0.2220, 0.2698, 0.2436\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and lf_Intellectual_Product.tsv matches\n",
      "0.4853, 0.4774, 0.9001, 0.7855, 0.8389, 0.0845, 0.1850, 0.1160\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and lf_Intellectual_Product.tsv matches\n",
      "0.4937, 0.4757, 0.9297, 0.7875, 0.8527, 0.0654, 0.2000, 0.0986\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and lf_Diagnostic_Procedure.tsv matches\n",
      "0.5023, 0.5015, 0.9038, 0.8822, 0.8929, 0.1001, 0.1225, 0.1102\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and lf_Diagnostic_Procedure.tsv matches\n",
      "0.5096, 0.5037, 0.9321, 0.8830, 0.9069, 0.0797, 0.1361, 0.1005\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and lf_Laboratory_Procedure.tsv matches\n",
      "0.5126, 0.5114, 0.9058, 0.8903, 0.8980, 0.1163, 0.1349, 0.1249\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and lf_Laboratory_Procedure.tsv matches\n",
      "0.5222, 0.5146, 0.9340, 0.8909, 0.9119, 0.0948, 0.1534, 0.1172\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and lf_Health_Care_Activity.tsv matches\n",
      "0.4951, 0.4839, 0.9023, 0.7865, 0.8404, 0.0926, 0.2036, 0.1273\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and lf_Health_Care_Activity.tsv matches\n",
      "0.5057, 0.4818, 0.9317, 0.7883, 0.8540, 0.0727, 0.2231, 0.1097\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and lf_Therapeutic_or_Preventive_Procedure.tsv matches\n",
      "0.5366, 0.5141, 0.9114, 0.8045, 0.8546, 0.1282, 0.2687, 0.1736\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and lf_Therapeutic_or_Preventive_Procedure.tsv matches\n",
      "0.5559, 0.5118, 0.9398, 0.8052, 0.8673, 0.1049, 0.3067, 0.1563\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and lf_Finding.tsv matches\n",
      "0.4804, 0.4625, 0.8986, 0.7216, 0.8004, 0.0842, 0.2392, 0.1245\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and lf_Finding.tsv matches\n",
      "0.4925, 0.4596, 0.9294, 0.7243, 0.8141, 0.0657, 0.2606, 0.1050\n",
      "--------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# full matches - Order free matches\n",
    "for count, i in enumerate(in_order):\n",
    "    \n",
    "    to_fetch = str(i).replace('lf_', '').replace('.tsv', '')\n",
    "    \n",
    "    base_preds = ob_matches[to_fetch]\n",
    "    base_preds_flattened =  flatten( base_preds )\n",
    "    \n",
    "    updated_of_preds = merge_preds_ordered( base_preds, orfs_dict[to_fetch] )\n",
    "    updated_preds_flattened =  flatten( updated_of_preds )\n",
    "    \n",
    "    # Classification report\n",
    "    cr_order_bound_coarse = classification_report( gt_coarse_flattened, updated_preds_flattened, digits=4, output_dict=True)\n",
    "    print(f'Confusion matrix for coarse-grained ground truth and {i} matches')\n",
    "    report = '{:.4f}, {:.4f}, {:.4f}, {:.4f}, {:.4f}, {:.4f}, {:.4f}, {:.4f}'.format(cr_order_bound_coarse['macro avg']['recall'], cr_order_bound_coarse['macro avg']['f1-score'], cr_order_bound_coarse['0']['precision'], cr_order_bound_coarse['0']['recall'], cr_order_bound_coarse['0']['f1-score'], cr_order_bound_coarse['1']['precision'], cr_order_bound_coarse['1']['recall'], cr_order_bound_coarse['1']['f1-score'])\n",
    "    print( report )\n",
    "\n",
    "    cr_order_bound_fine = classification_report( gt_fine_flattened, updated_preds_flattened, digits=4, output_dict=True)\n",
    "    print(f'\\n\\nConfusion matrix for fine-grained ground truth and {i} matches')\n",
    "    report = '{:.4f}, {:.4f}, {:.4f}, {:.4f}, {:.4f}, {:.4f}, {:.4f}, {:.4f}'.format(cr_order_bound_fine['macro avg']['recall'], cr_order_bound_fine['macro avg']['f1-score'], cr_order_bound_fine['0']['precision'], cr_order_bound_fine['0']['recall'], cr_order_bound_fine['0']['f1-score'], cr_order_bound_fine['1']['precision'], cr_order_bound_fine['1']['recall'], cr_order_bound_fine['1']['f1-score'])\n",
    "    print( report )\n",
    "    \n",
    "    print( '--------------------------------------------------------------------------' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d02eda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f1c149",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99af9b86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
