{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0206cc39",
   "metadata": {},
   "source": [
    "# Compare performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bf08083",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-95a1bff4e169>:11: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.*` instead of `tqdm._tqdm_notebook.*`\n",
      "  from tqdm._tqdm_notebook import tqdm_notebook\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import ast\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Sklearn imports\n",
    "from sklearn.metrics import f1_score, recall_score\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, auc, roc_curve\n",
    "\n",
    "from tqdm import tqdm\n",
    "from tqdm._tqdm_notebook import tqdm_notebook\n",
    "tqdm_notebook.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a3f992",
   "metadata": {},
   "source": [
    "## utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c963e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(d):\n",
    "    l = [ v for k,v in d.items() ]\n",
    "    l = [item for sublist in l for item in sublist]\n",
    "    l = list(map(int, l))\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54a16af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarize_fine(l):\n",
    "    binarized_labels = []\n",
    "    \n",
    "    for i in l:\n",
    "        if i > 1:\n",
    "            i = 1\n",
    "            binarized_labels.append( i )\n",
    "        else:\n",
    "            binarized_labels.append( i )\n",
    "    \n",
    "    return binarized_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9757bc9",
   "metadata": {},
   "source": [
    "## groundtruth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b6da53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load groundtruth for coarse matches\n",
    "\n",
    "gt_file = '/mnt/nas2/results/Results/systematicReview/order_free_matching/EBM_PICO_training_matches/order_bound/lf_Therapeutic_or_Preventive_Procedure.tsv'\n",
    "\n",
    "# open file and load into a dataframe\n",
    "groundtruth_df = pd.read_csv(gt_file, sep='\\t', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d1bf026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process the coarse and fine and add the pmid:gt to a ob dictionaries\n",
    "gt_coarse = dict()\n",
    "gt_fine = dict()\n",
    "\n",
    "for identifier, x, y in zip(groundtruth_df['pmid'], groundtruth_df['i'], groundtruth_df['i_f']):\n",
    "    x = ast.literal_eval(x)\n",
    "    y = ast.literal_eval(y)\n",
    "    \n",
    "    gt_coarse[str(identifier)] = x\n",
    "    gt_fine[str(identifier)] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59cea735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of PMIDs for groundtruth - coarse:  4802\n",
      "Total number of PMIDs for groundtruth - fine:  4802\n"
     ]
    }
   ],
   "source": [
    "print( 'Total number of PMIDs for groundtruth - coarse: ', len(gt_coarse) )\n",
    "print( 'Total number of PMIDs for groundtruth - fine: ', len(gt_fine) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3bd79485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten groundtruth\n",
    "\n",
    "gt_coarse_flattened = flatten( gt_coarse )\n",
    "gt_fine_flattened = flatten( gt_fine )\n",
    "\n",
    "# binarize the fine groundtruth labels\n",
    "gt_fine_flattened = binarize_fine(gt_fine_flattened)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4531a387",
   "metadata": {},
   "source": [
    "## order-bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a272e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load order bound matches for all dictionaries\n",
    "\n",
    "ob_dir = '/mnt/nas2/results/Results/systematicReview/order_free_matching/EBM_PICO_training_matches/order_bound'\n",
    "ob_files = os.listdir(ob_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3c7acbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:42<00:00,  2.23s/it]\n"
     ]
    }
   ],
   "source": [
    "ob_matches = dict()\n",
    "\n",
    "for i in tqdm(ob_files):\n",
    "    file_path = f'{ob_dir}/{i}'\n",
    "    \n",
    "    filename = str(i).replace('lf_', '')\n",
    "    filename = str(filename).replace('.tsv', '')\n",
    "    \n",
    "    # open file and load into a dataframe\n",
    "    data_df = pd.read_csv(file_path, sep='\\t', header=0)\n",
    "    \n",
    "    # process the labels and add the pmid:labels to a ob dictionary\n",
    "    labs_all = []\n",
    "    for x in data_df['labels']:\n",
    "        x = ast.literal_eval(x)\n",
    "        labs_all.append( x )\n",
    "    ob_matches[filename] = dict( zip( data_df['pmid'],  pd.Series( labs_all )) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82a4eaa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of PMIDs for orderbound files:  4802\n"
     ]
    }
   ],
   "source": [
    "print( 'Total number of PMIDs for orderbound files: ', len(ob_matches['Therapeutic_or_Preventive_Procedure']) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "01fe7a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(gt_fine) == len( ob_matches['Therapeutic_or_Preventive_Procedure'] ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4af7213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix for coarse-grained ground truth and lf_Intellectual_Product.tsv matches\n",
      "0.5084, 0.4959, 0.9048, 0.9917, 0.9463, 0.2454, 0.0251, 0.0455\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and lf_Intellectual_Product.tsv matches\n",
      "0.5108, 0.5067, 0.9321, 0.9916, 0.9610, 0.2103, 0.0300, 0.0525\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and lf_Intellectual_Product.tsv matches\n",
      "0.5155, 0.5110, 0.9061, 0.9841, 0.9435, 0.2400, 0.0469, 0.0785\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and lf_Intellectual_Product.tsv matches\n",
      "0.5207, 0.5241, 0.9335, 0.9840, 0.9580, 0.2105, 0.0574, 0.0903\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and lf_Intellectual_Product.tsv matches\n",
      "0.5038, 0.4921, 0.9040, 0.9821, 0.9414, 0.1320, 0.0254, 0.0427\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and lf_Intellectual_Product.tsv matches\n",
      "0.5061, 0.5018, 0.9315, 0.9822, 0.9562, 0.1117, 0.0300, 0.0474\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and lf_Intellectual_Product.tsv matches\n",
      "0.5715, 0.5919, 0.9163, 0.9742, 0.9444, 0.4122, 0.1688, 0.2395\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and lf_Intellectual_Product.tsv matches\n",
      "0.5927, 0.6140, 0.9432, 0.9733, 0.9580, 0.3714, 0.2122, 0.2701\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and lf_Intellectual_Product.tsv matches\n",
      "0.5024, 0.4871, 0.9038, 0.9877, 0.9439, 0.1302, 0.0171, 0.0303\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and lf_Intellectual_Product.tsv matches\n",
      "0.5037, 0.4960, 0.9312, 0.9878, 0.9587, 0.1072, 0.0197, 0.0333\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and lf_Intellectual_Product.tsv matches\n",
      "0.5460, 0.5563, 0.9117, 0.9656, 0.9379, 0.2821, 0.1265, 0.1747\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and lf_Intellectual_Product.tsv matches\n",
      "0.5588, 0.5698, 0.9387, 0.9648, 0.9516, 0.2443, 0.1529, 0.1881\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and lf_Intellectual_Product.tsv matches\n",
      "0.5577, 0.5757, 0.9137, 0.9820, 0.9466, 0.4416, 0.1334, 0.2049\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and lf_Intellectual_Product.tsv matches\n",
      "0.5750, 0.5989, 0.9407, 0.9812, 0.9605, 0.4003, 0.1687, 0.2374\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and lf_Intellectual_Product.tsv matches\n",
      "0.5072, 0.4925, 0.9046, 0.9940, 0.9472, 0.2676, 0.0204, 0.0378\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and lf_Intellectual_Product.tsv matches\n",
      "0.5094, 0.5034, 0.9320, 0.9939, 0.9620, 0.2339, 0.0248, 0.0449\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and lf_Intellectual_Product.tsv matches\n",
      "0.4853, 0.4824, 0.9006, 0.9249, 0.9126, 0.0610, 0.0456, 0.0522\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and lf_Intellectual_Product.tsv matches\n",
      "0.4855, 0.4858, 0.9287, 0.9257, 0.9272, 0.0434, 0.0453, 0.0443\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and lf_Intellectual_Product.tsv matches\n",
      "0.5000, 0.4746, 0.9033, 1.0000, 0.9492, 0.2000, 0.0000, 0.0000\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and lf_Intellectual_Product.tsv matches\n",
      "0.5000, 0.4821, 0.9307, 1.0000, 0.9641, 0.0000, 0.0000, 0.0000\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and lf_Intellectual_Product.tsv matches\n",
      "0.5009, 0.4955, 0.9035, 0.9581, 0.9300, 0.1006, 0.0438, 0.0610\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and lf_Intellectual_Product.tsv matches\n",
      "0.5012, 0.4998, 0.9309, 0.9581, 0.9443, 0.0731, 0.0444, 0.0552\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and lf_Intellectual_Product.tsv matches\n",
      "0.4802, 0.4800, 0.8992, 0.8351, 0.8660, 0.0752, 0.1254, 0.0940\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and lf_Intellectual_Product.tsv matches\n",
      "0.4851, 0.4802, 0.9284, 0.8368, 0.8803, 0.0573, 0.1334, 0.0802\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and lf_Intellectual_Product.tsv matches\n",
      "0.5136, 0.5043, 0.9057, 0.9940, 0.9478, 0.3721, 0.0331, 0.0608\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and lf_Intellectual_Product.tsv matches\n",
      "0.5167, 0.5165, 0.9329, 0.9937, 0.9624, 0.3202, 0.0397, 0.0707\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and lf_Intellectual_Product.tsv matches\n",
      "0.5017, 0.5016, 0.9037, 0.8972, 0.9004, 0.0995, 0.1062, 0.1028\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and lf_Intellectual_Product.tsv matches\n",
      "0.5071, 0.5040, 0.9318, 0.8979, 0.9145, 0.0781, 0.1163, 0.0935\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and lf_Intellectual_Product.tsv matches\n",
      "0.5025, 0.4826, 0.9038, 0.9958, 0.9476, 0.1906, 0.0093, 0.0177\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and lf_Intellectual_Product.tsv matches\n",
      "0.5038, 0.4922, 0.9312, 0.9958, 0.9624, 0.1730, 0.0118, 0.0221\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and lf_Intellectual_Product.tsv matches\n",
      "0.5056, 0.4906, 0.9043, 0.9921, 0.9462, 0.2051, 0.0192, 0.0351\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and lf_Intellectual_Product.tsv matches\n",
      "0.5078, 0.5013, 0.9317, 0.9920, 0.9610, 0.1804, 0.0235, 0.0416\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and lf_Intellectual_Product.tsv matches\n",
      "0.5077, 0.5028, 0.9047, 0.9682, 0.9354, 0.1371, 0.0472, 0.0702\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and lf_Intellectual_Product.tsv matches\n",
      "0.5101, 0.5101, 0.9321, 0.9681, 0.9498, 0.1085, 0.0522, 0.0705\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and lf_Intellectual_Product.tsv matches\n",
      "0.4984, 0.4826, 0.9031, 0.9827, 0.9412, 0.0805, 0.0141, 0.0240\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and lf_Intellectual_Product.tsv matches\n",
      "0.4981, 0.4887, 0.9305, 0.9828, 0.9559, 0.0545, 0.0133, 0.0214\n",
      "--------------------------------------------------------------------------\n",
      "Confusion matrix for coarse-grained ground truth and lf_Intellectual_Product.tsv matches\n",
      "0.4837, 0.4845, 0.9001, 0.8708, 0.8852, 0.0741, 0.0966, 0.0838\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and lf_Intellectual_Product.tsv matches\n",
      "0.4871, 0.4860, 0.9288, 0.8721, 0.8996, 0.0560, 0.1020, 0.0723\n",
      "--------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# calculate performance metrics for order-bound files\n",
    "\n",
    "for k, v in ob_matches.items():\n",
    "    \n",
    "    v_flattened = flatten( v )\n",
    "    \n",
    "    # Classification report\n",
    "    cr_order_bound_coarse = classification_report( gt_coarse_flattened, v_flattened, digits=4, output_dict=True)\n",
    "    print(f'Confusion matrix for coarse-grained ground truth and {k} matches')\n",
    "    report = '{:.4f}, {:.4f}, {:.4f}, {:.4f}, {:.4f}, {:.4f}, {:.4f}, {:.4f}'.format(cr_order_bound_coarse['macro avg']['recall'], cr_order_bound_coarse['macro avg']['f1-score'], cr_order_bound_coarse['0']['precision'], cr_order_bound_coarse['0']['recall'], cr_order_bound_coarse['0']['f1-score'], cr_order_bound_coarse['1']['precision'], cr_order_bound_coarse['1']['recall'], cr_order_bound_coarse['1']['f1-score'])\n",
    "    print( report )\n",
    "    \n",
    "\n",
    "    cr_order_bound_fine = classification_report( gt_fine_flattened, v_flattened, digits=4, output_dict=True)\n",
    "    print(f'\\n\\nConfusion matrix for fine-grained ground truth and {k} matches')\n",
    "    report = '{:.4f}, {:.4f}, {:.4f}, {:.4f}, {:.4f}, {:.4f}, {:.4f}, {:.4f}'.format(cr_order_bound_fine['macro avg']['recall'], cr_order_bound_fine['macro avg']['f1-score'], cr_order_bound_fine['0']['precision'], cr_order_bound_fine['0']['recall'], cr_order_bound_fine['0']['f1-score'], cr_order_bound_fine['1']['precision'], cr_order_bound_fine['1']['recall'], cr_order_bound_fine['1']['f1-score'])\n",
    "    print( report )\n",
    "    \n",
    "    print( '--------------------------------------------------------------------------' )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ff15d1",
   "metadata": {},
   "source": [
    "## order-free"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1349f7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load order free matches with all dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac880d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d42c99ca",
   "metadata": {},
   "source": [
    "## actual order-free"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3b6f0c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load (actual) order free matches with all dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fcc692",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
