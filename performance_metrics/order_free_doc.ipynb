{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59401921",
   "metadata": {},
   "source": [
    "# Order-free matching performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b89e1d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generic imports\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import ast\n",
    "import json\n",
    "\n",
    "\n",
    "# Sklearn imports\n",
    "from sklearn.metrics import f1_score, recall_score\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, auc, roc_curve\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52458f3",
   "metadata": {},
   "source": [
    "### Read order-free candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb9a9ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "picos = 'I' # ['P', 'I', 'O', 'S']\n",
    "match_level = 'doc' # ['doc', 'sent', 'win_5', 'para']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d3ca60",
   "metadata": {},
   "outputs": [],
   "source": [
    "order_free_dir = f'/mnt/nas2/results/Results/systematicReview/order_free_matching/EBM_PICO_training_matches/order_free/{match_level}/{picos}'\n",
    "order_free_files = os.listdir(order_free_dir)\n",
    "print('Files: ', order_free_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebf95be",
   "metadata": {},
   "outputs": [],
   "source": [
    "order_free_files.remove('.nfs0000000011200a4200000003')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae4c820",
   "metadata": {},
   "outputs": [],
   "source": [
    "orf_loaded_files = dict()\n",
    "\n",
    "for i in tqdm(order_free_files):\n",
    "    \n",
    "    filpath = f'{order_free_dir}/{i}'\n",
    "    print('Loading file...', i)\n",
    "    with open( filpath, 'r' ) as rf:\n",
    "        orf_i = json.load(rf)\n",
    "        orf_loaded_files[i] = orf_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0933bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_orf(orf, partial: bool):\n",
    "        \n",
    "    orf_doc_offsets = dict()\n",
    "\n",
    "    for i, (k, v) in enumerate(orf.items()):\n",
    "\n",
    "        if i == 0:\n",
    "            continue\n",
    "\n",
    "        if 'Inters. (full)' in v and len(v['Inters. (full)']) > 0 and len(v['tokens']) > 1:\n",
    "\n",
    "            for k_i, v_i in v['Inters. (full)'].items():\n",
    "\n",
    "                orf_doc_offsets[k_i] = []\n",
    "\n",
    "                if len( v_i['tokens'] ) > 1:\n",
    "\n",
    "                    source_tokens = v_i['tokens']\n",
    "                    source_offsets = v_i['char offs.']\n",
    "                    orf_doc_offsets[k_i].extend( source_offsets )\n",
    "                    \n",
    "        if partial == True:\n",
    "            \n",
    "            if 'Inters. (partial)' in v and len(v['Inters. (partial)']) > 0 and len(v['tokens']) > 1:\n",
    "\n",
    "                for k_i, v_i in v['Inters. (partial)'].items():\n",
    "\n",
    "                    orf_doc_offsets[k_i] = []\n",
    "\n",
    "                    if len( v_i['tokens'] ) > 1:\n",
    "\n",
    "                        source_tokens = v_i['tokens']\n",
    "                        source_offsets = v_i['char offs.']\n",
    "                        orf_doc_offsets[k_i].extend( source_offsets )\n",
    "            \n",
    "    \n",
    "    return orf_doc_offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9391079",
   "metadata": {},
   "outputs": [],
   "source": [
    "orf_int_syn_offsets_par = get_orf(orf_loaded_files['train_ebm_intervention_syn.json'], partial = True)\n",
    "orf_int_syn_offsets_full = get_orf(orf_loaded_files['train_ebm_intervention_syn.json'], partial = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6dd3d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "orf_int_offsets_par = get_orf(orf_loaded_files['train_ebm_intervention.json'], partial = True)\n",
    "orf_int_offsets_full = get_orf(orf_loaded_files['train_ebm_intervention.json'], partial = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99a206b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(orf_int_syn_offsets_par))\n",
    "print(len(orf_int_syn_offsets_full))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c574ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(orf_int_offsets_par))\n",
    "print(len(orf_int_offsets_full))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3289a609",
   "metadata": {},
   "source": [
    "### Merge dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533f805a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FullMergeDict(D1, D2):\n",
    "    \n",
    "    for key, value in D1.items():\n",
    "        if key in D2:\n",
    "            if type(value) is dict:\n",
    "                FullMergeDict(D1[key], D2[key])\n",
    "            else:\n",
    "                if type(value) in (int, float, str):\n",
    "                    D1[key] = [value]\n",
    "                if type(D2[key]) is list:\n",
    "                    D1[key].extend(D2[key])\n",
    "                else:\n",
    "                    D1[key].append(D2[key])\n",
    "    for key, value in D2.items():\n",
    "        if key not in D1:\n",
    "            D1[key] = value\n",
    "            \n",
    "    return D1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e368cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_dics(D1, D2):\n",
    "    \n",
    "    for k,v in D2.items():\n",
    "        if k in D1:\n",
    "            #merge the values\n",
    "            D2_val = D2[k]\n",
    "            D1[k].extend( D2_val )\n",
    "        else:\n",
    "            D1[k] = v\n",
    "    \n",
    "    return D1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc542e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "orf_offsets_par_merged = merge_dics(orf_int_syn_offsets_par, orf_int_offsets_par)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4844c300",
   "metadata": {},
   "outputs": [],
   "source": [
    "print( len(orf_offsets_par_merged) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852d5da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print( len(orf_offsets_par_merged) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e48f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "orf_offsets_full_merged = merge_dics(orf_int_syn_offsets_full, orf_int_offsets_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7d412f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print( len(orf_offsets_full_merged) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b7320c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print( len(orf_offsets_full_merged) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b12e929",
   "metadata": {},
   "source": [
    "### Load order-bound matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3afaa96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def order_free_matches(x, orf_offsets):\n",
    "    \n",
    "    labs_modified = []\n",
    "    \n",
    "    for i, (identifier, offs, labs) in enumerate( zip(x.pmid, x.offsets, x.labels) ):\n",
    "             \n",
    "        lab_val = [v for k, v in ast.literal_eval(labs).items()] \n",
    "        off_val = ast.literal_eval(offs) \n",
    "        \n",
    "        if str(identifier) in orf_offsets: \n",
    "            orf_matches =  orf_offsets[ str(identifier) ]\n",
    "            match_indices = [ off_val.index(m) for m in orf_matches ]\n",
    "            for i, l in enumerate(lab_val):\n",
    "                if i in match_indices:\n",
    "                    lab_val[i] = 1\n",
    "                    \n",
    "        labs_modified.append( lab_val )\n",
    "        \n",
    "        \n",
    "    return labs_modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3f5366",
   "metadata": {},
   "outputs": [],
   "source": [
    "order_bound_file = f'/mnt/nas2/results/Results/systematicReview/order_free_matching/EBM_PICO_training_matches/direct/{picos}/lf_ds_intervention_syn.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6796b351",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(order_bound_file, sep='\\t', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d87659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch ground truth\n",
    "\n",
    "# coarse\n",
    "picos_coarse_ = data[str(picos.lower())]\n",
    "picos_coarse = [ l for ent_series in picos_coarse_ for l in ast.literal_eval(ent_series) ]\n",
    "\n",
    "# fine\n",
    "picos_fine_ = data[ str(picos.lower()) + '_f' ]\n",
    "picos_fine = [ l for ent_series in picos_fine_ for l in ast.literal_eval(ent_series) ]\n",
    "picos_fine = ['1' if (n != '1' and n != '0') else str(n) for i, n in enumerate(picos_fine) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0ef21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch order-bound predictions\n",
    "\n",
    "preds = [ v for ent_series in data['labels'] for k, v in ast.literal_eval(ent_series).items() ]\n",
    "order_bound_preds = ['0' if n == -1 else str(n) for i, n in enumerate(preds) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a6ecee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch order-free predictions (dictionary int_syn)\n",
    "\n",
    "# ORF with partial\n",
    "data['orf_labels_partial'] = order_free_matches( data, orf_int_syn_offsets_par )\n",
    "preds_orf_doc_partial = [ v for ent_series in data['orf_labels_partial'] for v in ent_series ]\n",
    "order_free_partial_preds = ['0' if n == -1 else str(n) for i, n in enumerate(preds_orf_doc_partial) ]\n",
    "\n",
    "# ORF with full\n",
    "data['orf_labels_full'] = order_free_matches( data, orf_int_syn_offsets_full )\n",
    "preds_orf_doc_full = [ v for ent_series in data['orf_labels_full'] for v in ent_series ]\n",
    "order_free_full_preds = ['0' if n == -1 else str(n) for i, n in enumerate(preds_orf_doc_full) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea3a1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch order-free predictions (dictionary expansion int + int_syn)\n",
    "\n",
    "# ORF with partial\n",
    "data['orf_labels_merged_partial'] = order_free_matches( data, orf_offsets_par_merged )\n",
    "preds_orf_merged_partial = [ v for ent_series in data['orf_labels_merged_partial'] for v in ent_series ]\n",
    "order_free_merged_partial_preds = ['0' if n == -1 else str(n) for i, n in enumerate(preds_orf_merged_partial) ]\n",
    "\n",
    "# ORF with full\n",
    "data['orf_labels_merged_full'] = order_free_matches( data, orf_offsets_full_merged )\n",
    "preds_orf_merged_full = [ v for ent_series in data['orf_labels_merged_full'] for v in ent_series ]\n",
    "order_free_merged_full_preds = ['0' if n == -1 else str(n) for i, n in enumerate(preds_orf_merged_full) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c4543a",
   "metadata": {},
   "source": [
    "### evaluation metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56dfc28d",
   "metadata": {},
   "source": [
    "##### direct matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91402349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report\n",
    "cr_order_bound_coarse = classification_report( picos_coarse, order_bound_preds, digits=4  )\n",
    "print('Confusion matrix for coarse-grained ground truth and order-bound matches')\n",
    "print( cr_order_bound_coarse )\n",
    "\n",
    "cr_order_bound_fine = classification_report( picos_fine, order_bound_preds, digits=4  )\n",
    "print('\\n\\nConfusion matrix for fine-grained ground truth and order-bound matches')\n",
    "print( cr_order_bound_fine )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11af53d4",
   "metadata": {},
   "source": [
    "#### ORF matching - int_syn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11823a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report\n",
    "cr_order_free_doc_full_coarse = classification_report( picos_coarse, order_free_partial_preds, digits=4  )\n",
    "print('Confusion matrix for coarse-grained ground truth and document level order-free matches')\n",
    "print( cr_order_free_doc_full_coarse )\n",
    "\n",
    "cr_order_free_doc_full_fine = classification_report( picos_fine, order_free_partial_preds, digits=4  )\n",
    "print('\\n\\nConfusion matrix for fine-grained ground truth and document level order-free matches')\n",
    "print( cr_order_free_doc_full_fine )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0b84a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report\n",
    "cr_order_free_merged_full_coarse = classification_report( picos_coarse, order_free_merged_partial_preds, digits=4  )\n",
    "print('Confusion matrix for coarse-grained ground truth and document level order-free matches')\n",
    "print( cr_order_free_merged_full_coarse )\n",
    "\n",
    "cr_order_free_merged_full_fine = classification_report( picos_fine, order_free_merged_partial_preds, digits=4  )\n",
    "print('\\n\\nConfusion matrix for fine-grained ground truth and document level order-free matches')\n",
    "print( cr_order_free_merged_full_fine )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ad1f10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44151bf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07eb47a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae6f277",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbdcd8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5922a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report\n",
    "cr_order_free_doc_partial_coarse = classification_report( picos_coarse, order_free_full_preds, digits=4  )\n",
    "print('Confusion matrix for coarse-grained ground truth and document level order-free (partial) matches')\n",
    "print( cr_order_free_doc_partial_coarse )\n",
    "\n",
    "cr_order_free_doc_partial_fine = classification_report( picos_fine, order_free_doc_full_preds, digits=4  )\n",
    "print('\\n\\nConfusion matrix for fine-grained ground truth and document level order-free (partial) matches')\n",
    "print( cr_order_free_doc_partial_fine )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21dcc6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report\n",
    "cr_order_free_merged_partial_coarse = classification_report( picos_coarse, order_free_merged_full_preds, digits=4  )\n",
    "print('Confusion matrix for coarse-grained ground truth and document level order-free (partial) matches')\n",
    "print( cr_order_free_merged_partial_coarse )\n",
    "\n",
    "cr_order_free_merged_partial_fine = classification_report( picos_fine, order_free_merged_full_preds, digits=4  )\n",
    "print('\\n\\nConfusion matrix for fine-grained ground truth and document level order-free (partial) matches')\n",
    "print( cr_order_free_merged_partial_fine )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c59e548",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfe7aff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
