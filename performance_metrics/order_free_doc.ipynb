{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59401921",
   "metadata": {},
   "source": [
    "# Order-free matching performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b89e1d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generic imports\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import ast\n",
    "import json\n",
    "\n",
    "\n",
    "# Sklearn imports\n",
    "from sklearn.metrics import f1_score, recall_score\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, auc, roc_curve\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52458f3",
   "metadata": {},
   "source": [
    "## Read order-free candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb9a9ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "picos = 'I' # ['P', 'I', 'O', 'S']\n",
    "match_level = 'doc' # ['doc', 'sent', 'win_5', 'para']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f6ee90f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files:  ['.nfs0000000011200a4200000003', 'train_ebm_intervention.json', 'train_ebm_intervention_syn.json']\n"
     ]
    }
   ],
   "source": [
    "order_free_dir = f'/mnt/nas2/results/Results/systematicReview/order_free_matching/EBM_PICO_training_matches/order_free/{match_level}/{picos}'\n",
    "order_free_files = os.listdir(order_free_dir)\n",
    "print('Files: ', order_free_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09ac7c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "order_free_files.remove('.nfs0000000011200a4200000003')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6048509a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file... train_ebm_intervention.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 1/2 [00:13<00:13, 13.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file... train_ebm_intervention_syn.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:19<00:00,  9.52s/it]\n"
     ]
    }
   ],
   "source": [
    "orf_loaded_files = dict()\n",
    "\n",
    "for i in tqdm(order_free_files):\n",
    "    \n",
    "    filpath = f'{order_free_dir}/{i}'\n",
    "    print('Loading file...', i)\n",
    "    with open( filpath, 'r' ) as rf:\n",
    "        orf_i = json.load(rf)\n",
    "        orf_loaded_files[i] = orf_i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8806c358",
   "metadata": {},
   "source": [
    "## difference between intervention and intervention syn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82db3489",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_orf(v, par):\n",
    "    \n",
    "    orfs = dict()\n",
    "    \n",
    "    for k_i, v_i in v.items():\n",
    "        # print( k_i ) # example: name_15_3, name_9_9, name_12_8\n",
    "        \n",
    "        if 'Inters. (full)' in v_i and len(v_i['Inters. (full)']) > 0:\n",
    "            \n",
    "            full_inters = v_i['Inters. (full)']\n",
    "            # full_inters.keys() = PMIDs\n",
    "            # full_inters.values() = offsets, tokens\n",
    "\n",
    "            for pmid, matches in full_inters.items():\n",
    "                if len(matches['char offs.']) > 1:\n",
    "                    if pmid not in orfs:\n",
    "                        orfs[pmid] = [ ]\n",
    "                        orfs[pmid].extend( matches['word offs.'] )\n",
    "                    else:\n",
    "                        orfs[pmid].extend( matches['word offs.'] )\n",
    "\n",
    "\n",
    "        if 'Inters. (partial)' in v_i and len(v_i['Inters. (partial)']) > 0 and (par=='both' or par==True):\n",
    "            \n",
    "            par_inters = v_i['Inters. (partial)']\n",
    "            \n",
    "            for pmid, matches in par_inters.items():\n",
    "                if len(matches['char offs.']) > 1:\n",
    "                    if pmid not in orfs:\n",
    "                        orfs[pmid] = [ ]\n",
    "                        orfs[pmid].extend( matches['word offs.'] )\n",
    "                    else:\n",
    "                        orfs[pmid].extend( matches['word offs.'] )\n",
    "    \n",
    "    return orfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9fa10be",
   "metadata": {},
   "outputs": [],
   "source": [
    "orf_int_syn = get_orf(orf_loaded_files['train_ebm_intervention_syn.json'], par = True)\n",
    "orf_int = get_orf(orf_loaded_files['train_ebm_intervention.json'], par = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6806d6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_offsets_syn = []\n",
    "for k,v in orf_int_syn.items():\n",
    "    total_offsets_syn.extend( v )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a26169b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107195"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(total_offsets_syn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f2d3057",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_offsets = []\n",
    "for k,v in orf_int.items():\n",
    "    total_offsets.extend( v )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a2b83e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28661"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(total_offsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "738855d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107195\n",
      "28661\n"
     ]
    }
   ],
   "source": [
    "# just full\n",
    "print(len(total_offsets_syn))\n",
    "print(len(total_offsets))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af52935",
   "metadata": {},
   "source": [
    "## Merge dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "78483d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FullMergeDict(D1, D2):\n",
    "    \n",
    "    D_merged = dict()\n",
    "    \n",
    "    for k,v in D1.items():\n",
    "        \n",
    "        if k not in D_merged:\n",
    "            D_merged[k] = []\n",
    "            D_merged[k].extend( v )\n",
    "        else:\n",
    "            D_merged[k].extend( v )\n",
    "\n",
    "    for k,v in D2.items():\n",
    "        \n",
    "        if k not in D_merged:\n",
    "            D_merged[k] = []\n",
    "            D_merged[k].extend( v )\n",
    "        else:\n",
    "            D_merged[k].extend( v )\n",
    "            \n",
    "    return D_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6fc48432",
   "metadata": {},
   "outputs": [],
   "source": [
    "orfs_merged = FullMergeDict( orf_int, orf_int_syn )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e962143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total offsets after the int. and int. syn offsets were merged:  135856\n"
     ]
    }
   ],
   "source": [
    "total_offsets_merged = []\n",
    "for k,v in orfs_merged.items():\n",
    "    total_offsets_merged.extend( v )\n",
    "    \n",
    "print('Total offsets after the int. and int. syn offsets were merged: ', len(total_offsets_merged) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b12e929",
   "metadata": {},
   "source": [
    "## Load order-bound matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3afaa96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def order_free_matches(x, orf_offsets):\n",
    "    \n",
    "    labs_modified = []\n",
    "    \n",
    "    for i, (identifier, offs, labs) in enumerate( zip(x.pmid, x.offsets, x.labels) ):\n",
    "             \n",
    "        lab_val = [v for k, v in ast.literal_eval(labs).items()] \n",
    "        off_val = ast.literal_eval(offs) \n",
    "        \n",
    "        if str(identifier) in orf_offsets: \n",
    "            orf_matches =  orf_offsets[ str(identifier) ]\n",
    "            match_indices = [ off_val.index(m) for m in orf_matches ]\n",
    "            for i, l in enumerate(lab_val):\n",
    "                if i in match_indices:\n",
    "                    lab_val[i] = 1\n",
    "                    \n",
    "        labs_modified.append( lab_val )\n",
    "        \n",
    "        \n",
    "    return labs_modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ed3f5366",
   "metadata": {},
   "outputs": [],
   "source": [
    "ob_int = f'/mnt/nas2/results/Results/systematicReview/order_free_matching/EBM_PICO_training_matches/direct/{picos}/lf_ds_intervention_syn.tsv'\n",
    "ob_int_syn = f'/mnt/nas2/results/Results/systematicReview/order_free_matching/EBM_PICO_training_matches/direct/{picos}/lf_ds_intervetion.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6796b351",
   "metadata": {},
   "outputs": [],
   "source": [
    "ob_int_df = pd.read_csv(ob_int, sep='\\t', header=0)\n",
    "ob_int_syn_df = pd.read_csv(ob_int_syn, sep='\\t', header=0)\n",
    "ob_merged_df = pd.concat([ob_int_df,ob_int_syn_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "77ed857b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_gt(l):\n",
    "    \n",
    "    labels = l\n",
    "    \n",
    "    if isinstance(labels, str):\n",
    "        labels = ast.literal_eval(labels)\n",
    "        \n",
    "    # convert non-1 fine labels labels to 1's\n",
    "    labels = ['1' if (n != '1' and n != '0') else str(n) for i, n in enumerate(labels) ]\n",
    "    \n",
    "    return labels\n",
    "\n",
    "ob_int_df['i'] = ob_int_df.i.apply(process_gt)\n",
    "ob_int_syn_df['i'] = ob_int_syn_df.i.apply(process_gt)\n",
    "\n",
    "ob_int_df['i_f'] = ob_int_df.i_f.apply(process_gt)\n",
    "ob_int_syn_df['i_f'] = ob_int_syn_df.i_f.apply(process_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "63b15606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch ground truth from the direct matching\n",
    "\n",
    "coarse_int_gt = dict(zip(ob_int_df['pmid'], ob_int_df['i']))\n",
    "fine_int_gt = dict(zip(ob_int_df['pmid'], ob_int_df['i_f']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a798bd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess order-bound labels\n",
    "\n",
    "def process_ob_labs(l):\n",
    "    \n",
    "    labels = l\n",
    "    \n",
    "    if isinstance( labels, str ):\n",
    "        labels = ast.literal_eval(labels)\n",
    "\n",
    "    labels = [ v for k, v in labels.items() ]\n",
    "    labels = ['0' if n == -1 else str(n) for i, n in enumerate(labels) ]\n",
    "\n",
    "    return labels\n",
    "\n",
    "ob_int_df['labels'] = ob_int_df.labels.apply(process_ob_labs) # order bound matching labels for int source\n",
    "ob_int_syn_df['labels'] = ob_int_syn_df.labels.apply(process_ob_labs) # order bound matching labels for int_syn source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "372962ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch order-bound predictions for merged dataframes\n",
    "\n",
    "ob_preds_merged = dict()\n",
    "\n",
    "ob_int_dict = dict(zip(ob_int_df['pmid'], ob_int_df['labels']))\n",
    "ob_int_syn_dict = dict(zip(ob_int_syn_df['pmid'], ob_int_syn_df['labels']))\n",
    "\n",
    "for k,v in ob_int_dict.items():\n",
    "\n",
    "    if k not in ob_preds_merged:\n",
    "        ob_preds_merged[k] = []\n",
    "        ob_preds_merged[k] = v\n",
    "\n",
    "    else:\n",
    "        old_pred = ob_preds_merged[k]\n",
    "        new_pred = v\n",
    "        \n",
    "        # merge old and new predictions\n",
    "        merged_predictions = [ max( o,n ) for o,n in zip( old_pred, new_pred ) ]\n",
    "        assert len( old_pred ) == len( new_pred ) == len( merged_predictions )\n",
    "        ob_preds_merged[k] = merged_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c995ed43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4802"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len( list(ob_preds_merged.values()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5290fa3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in ob_int_syn_dict.items():\n",
    "\n",
    "    if k not in ob_preds_merged:\n",
    "        ob_preds_merged[k] = []\n",
    "        ob_preds_merged[k] = v\n",
    "\n",
    "    else:\n",
    "        old_pred = ob_preds_merged[k]\n",
    "        new_pred = v\n",
    "\n",
    "        # merge old and new predictions\n",
    "        #print( 'merging the new predictions...' )\n",
    "        merged_predictions = [ max( o,n ) for o,n in zip( old_pred, new_pred ) ]\n",
    "        assert len( old_pred ) == len( new_pred ) == len( merged_predictions )\n",
    "        ob_preds_merged[k] = merged_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e247ec5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1303169\n"
     ]
    }
   ],
   "source": [
    "total_total = []\n",
    "for k,v in ob_preds_merged.items():\n",
    "    total_total.extend( v )\n",
    "    \n",
    "print( len(total_total) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4642dc",
   "metadata": {},
   "source": [
    "## Merge ob preds with orf preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "478e41d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_preds_ordered( ob_preds, orf_offsets ):\n",
    "    \n",
    "    merged_predictions = dict()\n",
    "    \n",
    "    for k, v in ob_preds.items():\n",
    "        \n",
    "        k = str(k)\n",
    "\n",
    "        if k in orf_offsets:\n",
    "            matching_offsets = orf_offsets[k]\n",
    "            old_preds = list( map( int, v ))\n",
    "            new_preds = list( map( int, v ))\n",
    "                             \n",
    "            # add new offsets to the new_preds\n",
    "            for indice in matching_offsets:\n",
    "                new_preds[indice] = 1\n",
    "\n",
    "            merged_predictions[ k ] = new_preds\n",
    "        else:\n",
    "            merged_predictions[ k ] = list( map( int, v ) )\n",
    "    \n",
    "    return merged_predictions\n",
    "                             \n",
    "                             \n",
    "ob_of_int = merge_preds_ordered( ob_preds_merged, orf_int )\n",
    "ob_of_int_syn = merge_preds_ordered( ob_preds_merged, orf_int_syn )\n",
    "ob_of_int_merged = merge_preds_ordered( ob_preds_merged, orfs_merged )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eb483fcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1303169\n"
     ]
    }
   ],
   "source": [
    "total_total = []\n",
    "for k,v in ob_of_int_syn.items():\n",
    "    total_total.extend( v )\n",
    "    \n",
    "print( len(total_total) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c4543a",
   "metadata": {},
   "source": [
    "## evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d2fb336c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(d):\n",
    "    l = [ v for k,v in d.items() ]\n",
    "    l = [item for sublist in l for item in sublist]\n",
    "    l = list(map(int, l))\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b642e2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ground truth : coarse_int_gt, fine_int_gt\n",
    "# ob/direct matching preds :  ob_preds_merged\n",
    "\n",
    "order_bound_preds = flatten( ob_preds_merged )\n",
    "picos_coarse = flatten( coarse_int_gt )\n",
    "picos_fine = flatten( fine_int_gt )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56dfc28d",
   "metadata": {},
   "source": [
    "##### direct matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "91402349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix for coarse-grained ground truth and order-bound matches\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9295    0.7394    0.8236   1177209\n",
      "           1     0.1635    0.4761    0.2434    125960\n",
      "\n",
      "    accuracy                         0.7139   1303169\n",
      "   macro avg     0.5465    0.6077    0.5335   1303169\n",
      "weighted avg     0.8555    0.7139    0.7675   1303169\n",
      "\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and order-bound matches\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9565    0.7385    0.8335   1212904\n",
      "           1     0.1352    0.5492    0.2169     90265\n",
      "\n",
      "    accuracy                         0.7254   1303169\n",
      "   macro avg     0.5459    0.6438    0.5252   1303169\n",
      "weighted avg     0.8997    0.7254    0.7908   1303169\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report\n",
    "cr_order_bound_coarse = classification_report( picos_coarse, order_bound_preds, digits=4  )\n",
    "print('Confusion matrix for coarse-grained ground truth and order-bound matches')\n",
    "print( cr_order_bound_coarse )\n",
    "\n",
    "cr_order_bound_fine = classification_report( picos_fine, order_bound_preds, digits=4  )\n",
    "print('\\n\\nConfusion matrix for fine-grained ground truth and order-bound matches')\n",
    "print( cr_order_bound_fine )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dcb1183",
   "metadata": {},
   "source": [
    "#### ORF matching - int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b410fc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# order free matching preds - int : ob_of_int\n",
    "# order free matching preds - int_syn : ob_of_int_syn\n",
    "# order free matching preds - merged : ob_of_int_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "50bf38c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ob_of_int_preds = flatten( ob_of_int )\n",
    "ob_of_int_syn_preds = flatten( ob_of_int_syn )\n",
    "ob_of_int_merged_preds = flatten( ob_of_int_merged )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e11823a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix for coarse-grained ground truth and (int.) document level order-free matches\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9295    0.7369    0.8221   1177209\n",
      "           1     0.1627    0.4780    0.2428    125960\n",
      "\n",
      "    accuracy                         0.7119   1303169\n",
      "   macro avg     0.5461    0.6074    0.5324   1303169\n",
      "weighted avg     0.8554    0.7119    0.7661   1303169\n",
      "\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and (int.) document level order-free matches\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9566    0.7360    0.8319   1212904\n",
      "           1     0.1345    0.5512    0.2162     90265\n",
      "\n",
      "    accuracy                         0.7232   1303169\n",
      "   macro avg     0.5455    0.6436    0.5241   1303169\n",
      "weighted avg     0.8996    0.7232    0.7893   1303169\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report\n",
    "cr_orf_int_coarse = classification_report( picos_coarse, ob_of_int_preds, digits=4  )\n",
    "print('Confusion matrix for coarse-grained ground truth and (int.) document level order-free matches')\n",
    "print( cr_orf_int_coarse )\n",
    "\n",
    "cr_orf_int_fine = classification_report( picos_fine, ob_of_int_preds, digits=4  )\n",
    "print('\\n\\nConfusion matrix for fine-grained ground truth and (int.) document level order-free matches')\n",
    "print( cr_orf_int_fine )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4c59e548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix for coarse-grained ground truth and (int syn.) document level order-free matches\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9296    0.7333    0.8199   1177209\n",
      "           1     0.1617    0.4807    0.2420    125960\n",
      "\n",
      "    accuracy                         0.7089   1303169\n",
      "   macro avg     0.5456    0.6070    0.5309   1303169\n",
      "weighted avg     0.8554    0.7089    0.7640   1303169\n",
      "\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and (int syn.) document level order-free matches\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9566    0.7325    0.8297   1212904\n",
      "           1     0.1335    0.5539    0.2152     90265\n",
      "\n",
      "    accuracy                         0.7201   1303169\n",
      "   macro avg     0.5451    0.6432    0.5224   1303169\n",
      "weighted avg     0.8996    0.7201    0.7871   1303169\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report\n",
    "cr_orf_intsyn_coarse = classification_report( picos_coarse, ob_of_int_syn_preds, digits=4  )\n",
    "print('Confusion matrix for coarse-grained ground truth and (int syn.) document level order-free matches')\n",
    "print( cr_orf_intsyn_coarse )\n",
    "\n",
    "cr_orf_intsyn_fine = classification_report( picos_fine, ob_of_int_syn_preds, digits=4  )\n",
    "print('\\n\\nConfusion matrix for fine-grained ground truth and (int syn.) document level order-free matches')\n",
    "print( cr_orf_intsyn_fine )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0cfe7aff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix for coarse-grained ground truth and (merged.) document level order-free matches\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9296    0.7314    0.8187   1177209\n",
      "           1     0.1611    0.4821    0.2415    125960\n",
      "\n",
      "    accuracy                         0.7073   1303169\n",
      "   macro avg     0.5453    0.6068    0.5301   1303169\n",
      "weighted avg     0.8553    0.7073    0.7629   1303169\n",
      "\n",
      "\n",
      "\n",
      "Confusion matrix for fine-grained ground truth and (merged.) document level order-free matches\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9567    0.7306    0.8285   1212904\n",
      "           1     0.1330    0.5553    0.2146     90265\n",
      "\n",
      "    accuracy                         0.7184   1303169\n",
      "   macro avg     0.5448    0.6429    0.5215   1303169\n",
      "weighted avg     0.8996    0.7184    0.7859   1303169\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report\n",
    "cr_orf_intmerged_coarse = classification_report( picos_coarse, ob_of_int_merged_preds, digits=4  )\n",
    "print('Confusion matrix for coarse-grained ground truth and (merged.) document level order-free matches')\n",
    "print( cr_orf_intmerged_coarse )\n",
    "\n",
    "cr_orf_intmerged_fine = classification_report( picos_fine, ob_of_int_merged_preds, digits=4  )\n",
    "print('\\n\\nConfusion matrix for fine-grained ground truth and (merged.) document level order-free matches')\n",
    "print( cr_orf_intmerged_fine )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80391677",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
